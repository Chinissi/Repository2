import os
import sqlite3
import typing
from logging import Logger
from typing import (
    TYPE_CHECKING,
    AbstractSet,
    Any,
    Callable,
    ClassVar,
    Hashable,
    Iterable,
    List,
    Mapping,
    MutableSequence,
    Sequence,
    Set,
    Type,
    TypeVar,
    Union,
)

import pandas as pd
import pydantic
import sqlalchemy  # noqa: TID251
from typing_extensions import Literal

from great_expectations.datasource.fluent.interfaces import (
    Batch,
    BatchMetadata,
    BatchRequest,
    BatchRequestOptions,
    DataAsset,
    Datasource,
)

if TYPE_CHECKING:
    from great_expectations.datasource.fluent.dynamic_pandas import (
        CompressionOptions,
        CSVEngine,
        FilePath,
        IndexLabel,
        StorageOptions,
    )
    from great_expectations.execution_engine import (
        PandasExecutionEngine,
    )
    from great_expectations.validator.validator import Validator

_EXCLUDE_TYPES_FROM_JSON: list[Type]

MappingIntStrAny = Mapping[Union[int, str], Any]
AbstractSetIntStr = AbstractSet[Union[int, str]]
logger: Logger
_PandasDataFrameT = TypeVar("_PandasDataFrameT")

class PandasDatasourceError(Exception): ...

class _PandasDataAsset(DataAsset):
    _EXCLUDE_FROM_READER_OPTIONS: ClassVar[Set[str]]

    def _get_reader_method(self) -> str: ...
    def test_connection(self) -> None: ...
    def batch_request_options_template(self) -> BatchRequestOptions: ...
    def get_batch_list_from_batch_request(
        self, batch_request: BatchRequest
    ) -> list[Batch]: ...
    def build_batch_request(
        self, options: BatchRequestOptions | None = ...
    ) -> BatchRequest: ...
    def _validate_batch_request(self, batch_request: BatchRequest) -> None: ...
    def json(
        self,
        *,
        include: AbstractSetIntStr | MappingIntStrAny | None = ...,
        exclude: AbstractSetIntStr | MappingIntStrAny | None = ...,
        by_alias: bool = ...,
        skip_defaults: bool | None = ...,
        exclude_unset: bool = ...,
        exclude_defaults: bool = ...,
        exclude_none: bool = ...,
        encoder: Callable[[Any], Any] | None = ...,
        models_as_dict: bool = ...,
        **dumps_kwargs: Any,
    ) -> str: ...

class ClipboardAsset(_PandasDataAsset): ...
class CSVAsset(_PandasDataAsset): ...
class ExcelAsset(_PandasDataAsset): ...
class FeatherAsset(_PandasDataAsset): ...
class GBQAsset(_PandasDataAsset): ...
class HDFAsset(_PandasDataAsset): ...
class HTMLAsset(_PandasDataAsset): ...
class JSONAsset(_PandasDataAsset): ...
class ORCAsset(_PandasDataAsset): ...
class ParquetAsset(_PandasDataAsset): ...
class PickleAsset(_PandasDataAsset): ...
class SQLAsset(_PandasDataAsset): ...
class SQLQueryAsset(_PandasDataAsset): ...
class SQLTableAsset(_PandasDataAsset): ...
class SASAsset(_PandasDataAsset): ...
class SPSSAsset(_PandasDataAsset): ...
class StataAsset(_PandasDataAsset): ...
class TableAsset(_PandasDataAsset): ...
class XMLAsset(_PandasDataAsset): ...

class DataFrameAsset(_PandasDataAsset):
    type: Literal["dataframe"]
    dataframe: _PandasDataFrameT  # type: ignore[valid-type]

    def get_batch_list_from_batch_request(
        self, batch_request: BatchRequest
    ) -> list[Batch]: ...

_PandasDataAssetT = TypeVar("_PandasDataAssetT", bound=_PandasDataAsset)

class _PandasDatasource(Datasource):
    asset_types: ClassVar[Sequence[Type[DataAsset]]]
    assets: MutableSequence[_PandasDataAssetT]  # type: ignore[valid-type]
    @property
    def execution_engine_type(self) -> Type[PandasExecutionEngine]: ...
    def test_connection(self, test_assets: bool = ...) -> None: ...
    def json(
        self,
        *,
        include: AbstractSetIntStr | MappingIntStrAny | None = ...,
        exclude: AbstractSetIntStr | MappingIntStrAny | None = ...,
        by_alias: bool = ...,
        skip_defaults: bool | None = ...,
        exclude_unset: bool = ...,
        exclude_defaults: bool = ...,
        exclude_none: bool = ...,
        encoder: Callable[[Any], Any] | None = ...,
        models_as_dict: bool = ...,
        **dumps_kwargs: Any,
    ) -> str: ...

_DYNAMIC_ASSET_TYPES: list[Type[_PandasDataAsset]]

class PandasDatasource(_PandasDatasource):
    asset_types: ClassVar[Sequence[Type[DataAsset]]]
    type: Literal["pandas"]
    assets: List[_PandasDataAsset]
    def test_connection(self, test_assets: bool = ...) -> None: ...
    def add_dataframe_asset(
        self,
        name: str,
        dataframe: pd.DataFrame,
        *,
        batch_metadata: BatchMetadata | None = ...,
    ) -> DataFrameAsset: ...
    def read_dataframe(
        self,
        dataframe: pd.DataFrame,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
    ) -> Validator: ...
    def add_clipboard_asset(
        self,
        name: str,
        *,
        batch_metadata: BatchMetadata | None = ...,
        sep: str = "\\s+",
        kwargs: dict | None = ...,
    ) -> ClipboardAsset: ...
    def add_csv_asset(
        self,
        name: str,
        filepath_or_buffer: pydantic.FilePath | pydantic.AnyUrl,
        *,
        batch_metadata: BatchMetadata | None = ...,
        sep: str | None = ...,
        delimiter: str | None = ...,
        header: int | Sequence[int] | None | Literal["infer"] = "infer",
        names: Sequence[Hashable] | None = ...,
        index_col: IndexLabel | Literal[False] | None = ...,
        usecols: int | str | typing.Sequence[int] | None = ...,
        squeeze: bool | None = ...,
        prefix: str = ...,
        mangle_dupe_cols: bool = ...,
        dtype: dict | None = ...,
        engine: CSVEngine | None = ...,
        converters: typing.Any = ...,
        true_values: typing.Any = ...,
        false_values: typing.Any = ...,
        skipinitialspace: bool = ...,
        skiprows: typing.Sequence[int] | int | None = ...,
        skipfooter: int = 0,
        nrows: int | None = ...,
        na_values: typing.Any = ...,
        keep_default_na: bool = ...,
        na_filter: bool = ...,
        verbose: bool = ...,
        skip_blank_lines: bool = ...,
        parse_dates: typing.Any = ...,
        infer_datetime_format: bool = ...,
        keep_date_col: bool = ...,
        date_parser: typing.Any = ...,
        dayfirst: bool = ...,
        cache_dates: bool = ...,
        iterator: bool = ...,
        chunksize: int | None = ...,
        compression: CompressionOptions = "infer",
        thousands: str | None = ...,
        decimal: str = ".",
        lineterminator: str | None = ...,
        quotechar: str = '"',
        quoting: int = 0,
        doublequote: bool = ...,
        escapechar: str | None = ...,
        comment: str | None = ...,
        encoding: str | None = ...,
        encoding_errors: str | None = "strict",
        dialect: str | None = ...,
        error_bad_lines: bool | None = ...,
        warn_bad_lines: bool | None = ...,
        on_bad_lines: typing.Any = ...,
        delim_whitespace: bool = ...,
        low_memory: typing.Any = ...,
        memory_map: bool = ...,
        storage_options: StorageOptions = ...,
    ) -> CSVAsset: ...
    def add_excel_asset(
        self,
        name: str,
        io: os.PathLike | str | bytes,
        *,
        batch_metadata: BatchMetadata | None = ...,
        sheet_name: str | int | None = 0,
        header: int | Sequence[int] | None = 0,
        names: typing.List[str] | None = ...,
        index_col: int | Sequence[int] | None = ...,
        usecols: int | str | typing.Sequence[int] | None = ...,
        squeeze: bool | None = ...,
        dtype: dict | None = ...,
        true_values: Iterable[Hashable] | None = ...,
        false_values: Iterable[Hashable] | None = ...,
        skiprows: typing.Sequence[int] | int | None = ...,
        nrows: int | None = ...,
        na_values: typing.Any = ...,
        keep_default_na: bool = ...,
        na_filter: bool = ...,
        verbose: bool = ...,
        parse_dates: typing.List | typing.Dict | bool = ...,
        thousands: str | None = ...,
        decimal: str = ".",
        comment: str | None = ...,
        skipfooter: int = 0,
        convert_float: bool | None = ...,
        mangle_dupe_cols: bool = ...,
        storage_options: StorageOptions = ...,
    ) -> ExcelAsset: ...
    def add_feather_asset(
        self,
        name: str,
        path: pydantic.FilePath | pydantic.AnyUrl,
        *,
        batch_metadata: BatchMetadata | None = ...,
        columns: Sequence[Hashable] | None = ...,
        use_threads: bool = ...,
        storage_options: StorageOptions = ...,
    ) -> FeatherAsset: ...
    def add_gbq_asset(
        self,
        name: str,
        query: str,
        *,
        batch_metadata: BatchMetadata | None = ...,
        project_id: str | None = ...,
        index_col: str | None = ...,
        col_order: typing.List[str] | None = ...,
        reauth: bool = ...,
        auth_local_webserver: bool = ...,
        dialect: str | None = ...,
        location: str | None = ...,
        configuration: typing.Dict[str, typing.Any] | None = ...,
        credentials: typing.Any = ...,
        use_bqstorage_api: bool | None = ...,
        max_results: int | None = ...,
        progress_bar_type: str | None = ...,
    ) -> GBQAsset: ...
    def add_hdf_asset(
        self,
        name: str,
        path_or_buf: str | os.PathLike | pd.HDFStore,
        *,
        batch_metadata: BatchMetadata | None = ...,
        key: typing.Any = ...,
        mode: str = "r",
        errors: str = "strict",
        where: str | typing.List | None = ...,
        start: int | None = ...,
        stop: int | None = ...,
        columns: typing.List[str] | None = ...,
        iterator: bool = ...,
        chunksize: int | None = ...,
        kwargs: dict | None = ...,
    ) -> HDFAsset: ...
    def add_html_asset(
        self,
        name: str,
        io: os.PathLike | str,
        *,
        batch_metadata: BatchMetadata | None = ...,
        match: str | typing.Pattern = ".+",
        flavor: str | None = ...,
        header: int | Sequence[int] | None = ...,
        index_col: int | Sequence[int] | None = ...,
        skiprows: typing.Sequence[int] | int | None = ...,
        attrs: typing.Dict[str, str] | None = ...,
        parse_dates: bool = ...,
        thousands: str | None = ",",
        encoding: str | None = ...,
        decimal: str = ".",
        converters: typing.Dict | None = ...,
        na_values: Iterable[object] | None = ...,
        keep_default_na: bool = ...,
        displayed_only: bool = ...,
    ) -> HTMLAsset: ...
    def add_json_asset(
        self,
        name: str,
        path_or_buf: pydantic.Json | pydantic.FilePath | pydantic.AnyUrl,
        *,
        batch_metadata: BatchMetadata | None = ...,
        orient: str | None = ...,
        dtype: dict | None = ...,
        convert_axes: typing.Any = ...,
        convert_dates: bool | typing.List[str] = ...,
        keep_default_dates: bool = ...,
        numpy: bool = ...,
        precise_float: bool = ...,
        date_unit: str | None = ...,
        encoding: str | None = ...,
        encoding_errors: str | None = "strict",
        lines: bool = ...,
        chunksize: int | None = ...,
        compression: CompressionOptions = "infer",
        nrows: int | None = ...,
        storage_options: StorageOptions = ...,
    ) -> JSONAsset: ...
    def add_orc_asset(
        self,
        name: str,
        path: pydantic.FilePath | pydantic.AnyUrl,
        *,
        batch_metadata: BatchMetadata | None = ...,
        columns: typing.List[str] | None = ...,
        kwargs: dict | None = ...,
    ) -> ORCAsset: ...
    def add_parquet_asset(
        self,
        name: str,
        path: pydantic.FilePath | pydantic.AnyUrl,
        *,
        batch_metadata: BatchMetadata | None = ...,
        engine: str = "auto",
        columns: typing.List[str] | None = ...,
        storage_options: StorageOptions = ...,
        use_nullable_dtypes: bool = ...,
        kwargs: dict | None = ...,
    ) -> ParquetAsset | None: ...
    def add_pickle_asset(
        self,
        name: str,
        filepath_or_buffer: pydantic.FilePath | pydantic.AnyUrl,
        *,
        batch_metadata: BatchMetadata | None = ...,
        compression: CompressionOptions = "infer",
        storage_options: StorageOptions = ...,
    ) -> PickleAsset: ...
    def add_sas_asset(
        self,
        name: str,
        filepath_or_buffer: pydantic.FilePath | pydantic.AnyUrl,
        *,
        batch_metadata: BatchMetadata | None = ...,
        format: str | None = ...,
        index: Hashable | None = ...,
        encoding: str | None = ...,
        chunksize: int | None = ...,
        iterator: bool = ...,
        compression: CompressionOptions = "infer",
    ) -> SASAsset: ...
    def add_spss_asset(
        self,
        name: str,
        path: pydantic.FilePath,
        *,
        batch_metadata: BatchMetadata | None = ...,
        usecols: int | str | typing.Sequence[int] | None = ...,
        convert_categoricals: bool = ...,
    ) -> SPSSAsset: ...
    def add_sql_asset(
        self,
        name: str,
        sql: sqlalchemy.select | sqlalchemy.text | str,
        con: sqlalchemy.engine.Engine | sqlite3.Connection | str,
        *,
        batch_metadata: BatchMetadata | None = ...,
        index_col: str | typing.List[str] | None = ...,
        coerce_float: bool = ...,
        params: typing.Any = ...,
        parse_dates: typing.Any = ...,
        columns: typing.List[str] | None = ...,
        chunksize: int | None = ...,
    ) -> SQLAsset: ...
    def add_sql_query_asset(
        self,
        name: str,
        sql: sqlalchemy.select | sqlalchemy.text | str,
        con: sqlalchemy.engine.Engine | sqlite3.Connection | str,
        *,
        batch_metadata: BatchMetadata | None = ...,
        index_col: str | typing.List[str] | None = ...,
        coerce_float: bool = ...,
        params: typing.List[str] | typing.Dict[str, str] | None = ...,
        parse_dates: typing.List[str] | typing.Dict[str, str] | None = ...,
        chunksize: int | None = ...,
        dtype: dict | None = ...,
    ) -> SQLQueryAsset: ...
    def add_sql_table_asset(
        self,
        name: str,
        table_name: str,
        con: sqlalchemy.engine.Engine | str,
        *,
        batch_metadata: BatchMetadata | None = ...,
        schema: str | None = ...,
        index_col: str | typing.List[str] | None = ...,
        coerce_float: bool = ...,
        parse_dates: typing.List[str] | typing.Dict[str, str] | None = ...,
        columns: typing.List[str] | None = ...,
        chunksize: int | None = ...,
    ) -> SQLTableAsset: ...
    def add_stata_asset(
        self,
        name: str,
        filepath_or_buffer: pydantic.FilePath | pydantic.AnyUrl,
        *,
        batch_metadata: BatchMetadata | None = ...,
        convert_dates: bool = ...,
        convert_categoricals: bool = ...,
        index_col: str | None = ...,
        convert_missing: bool = ...,
        preserve_dtypes: bool = ...,
        columns: Sequence[str] | None = ...,
        order_categoricals: bool = ...,
        chunksize: int | None = ...,
        iterator: bool = ...,
        compression: CompressionOptions = "infer",
        storage_options: StorageOptions = ...,
    ) -> StataAsset: ...
    def add_table_asset(
        self,
        name: str,
        filepath_or_buffer: pydantic.FilePath | pydantic.AnyUrl,
        *,
        batch_metadata: BatchMetadata | None = ...,
        sep: str | None = ...,
        delimiter: str | None = ...,
        header: int | Sequence[int] | None | Literal["infer"] = "infer",
        names: Sequence[Hashable] | None = ...,
        index_col: IndexLabel | Literal[False] | None = ...,
        usecols: int | str | typing.Sequence[int] | None = ...,
        squeeze: bool | None = ...,
        prefix: str = ...,
        mangle_dupe_cols: bool = ...,
        dtype: dict | None = ...,
        engine: CSVEngine | None = ...,
        converters: typing.Any = ...,
        true_values: typing.Any = ...,
        false_values: typing.Any = ...,
        skipinitialspace: bool = ...,
        skiprows: typing.Sequence[int] | int | None = ...,
        skipfooter: int = 0,
        nrows: int | None = ...,
        na_values: typing.Any = ...,
        keep_default_na: bool = ...,
        na_filter: bool = ...,
        verbose: bool = ...,
        skip_blank_lines: bool = ...,
        parse_dates: typing.Any = ...,
        infer_datetime_format: bool = ...,
        keep_date_col: bool = ...,
        date_parser: typing.Any = ...,
        dayfirst: bool = ...,
        cache_dates: bool = ...,
        iterator: bool = ...,
        chunksize: int | None = ...,
        compression: CompressionOptions = "infer",
        thousands: str | None = ...,
        decimal: str = ".",
        lineterminator: str | None = ...,
        quotechar: str = '"',
        quoting: int = 0,
        doublequote: bool = ...,
        escapechar: str | None = ...,
        comment: str | None = ...,
        encoding: str | None = ...,
        encoding_errors: str | None = "strict",
        dialect: str | None = ...,
        error_bad_lines: bool | None = ...,
        warn_bad_lines: bool | None = ...,
        on_bad_lines: typing.Any = ...,
        delim_whitespace: typing.Any = ...,
        low_memory: typing.Any = ...,
        memory_map: bool = ...,
        float_precision: str | None = ...,
        storage_options: StorageOptions = ...,
    ) -> TableAsset: ...
    def add_xml_asset(
        self,
        name: str,
        path_or_buffer: pydantic.FilePath | pydantic.AnyUrl,
        *,
        batch_metadata: BatchMetadata | None = ...,
        xpath: str = "./*",
        namespaces: typing.Dict[str, str] | None = ...,
        elems_only: bool = ...,
        attrs_only: bool = ...,
        names: Sequence[str] | None = ...,
        dtype: dict | None = ...,
        encoding: str | None = "utf-8",
        stylesheet: FilePath | None = ...,
        iterparse: typing.Dict[str, typing.List[str]] | None = ...,
        compression: CompressionOptions = "infer",
        storage_options: StorageOptions = ...,
    ) -> XMLAsset: ...
    def read_clipboard(
        self,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        sep: str = r"\s+",
        kwargs: dict | None = ...,
    ) -> Validator: ...
    def read_csv(
        self,
        filepath_or_buffer: pydantic.FilePath | pydantic.AnyUrl,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        sep: str | None = ...,
        delimiter: str | None = ...,
        header: int | Sequence[int] | None | Literal["infer"] = "infer",
        names: Sequence[Hashable] | None = ...,
        index_col: IndexLabel | Literal[False] | None = ...,
        usecols: int | str | typing.Sequence[int] | None = ...,
        squeeze: bool | None = ...,
        prefix: str = ...,
        mangle_dupe_cols: bool = ...,
        dtype: dict | None = ...,
        engine: CSVEngine | None = ...,
        converters: typing.Any = ...,
        true_values: typing.Any = ...,
        false_values: typing.Any = ...,
        skipinitialspace: bool = ...,
        skiprows: typing.Sequence[int] | int | None = ...,
        skipfooter: int = 0,
        nrows: int | None = ...,
        na_values: typing.Any = ...,
        keep_default_na: bool = ...,
        na_filter: bool = ...,
        verbose: bool = ...,
        skip_blank_lines: bool = ...,
        parse_dates: typing.Any = ...,
        infer_datetime_format: bool = ...,
        keep_date_col: bool = ...,
        date_parser: typing.Any = ...,
        dayfirst: bool = ...,
        cache_dates: bool = ...,
        iterator: bool = ...,
        chunksize: int | None = ...,
        compression: CompressionOptions = "infer",
        thousands: str | None = ...,
        decimal: str = ".",
        lineterminator: str | None = ...,
        quotechar: str = '"',
        quoting: int = 0,
        doublequote: bool = ...,
        escapechar: str | None = ...,
        comment: str | None = ...,
        encoding: str | None = ...,
        encoding_errors: str | None = "strict",
        dialect: str | None = ...,
        error_bad_lines: bool | None = ...,
        warn_bad_lines: bool | None = ...,
        on_bad_lines: typing.Any = ...,
        delim_whitespace: bool = ...,
        low_memory: typing.Any = ...,
        memory_map: bool = ...,
        storage_options: StorageOptions = ...,
    ) -> Validator: ...
    def read_excel(
        self,
        io: os.PathLike | str | bytes,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        sheet_name: str | int | None = 0,
        header: int | Sequence[int] | None = 0,
        names: typing.List[str] | None = ...,
        index_col: int | Sequence[int] | None = ...,
        usecols: int | str | typing.Sequence[int] | None = ...,
        squeeze: bool | None = ...,
        dtype: dict | None = ...,
        true_values: Iterable[Hashable] | None = ...,
        false_values: Iterable[Hashable] | None = ...,
        skiprows: typing.Sequence[int] | int | None = ...,
        nrows: int | None = ...,
        na_values: typing.Any = ...,
        keep_default_na: bool = ...,
        na_filter: bool = ...,
        verbose: bool = ...,
        parse_dates: typing.List | typing.Dict | bool = ...,
        thousands: str | None = ...,
        decimal: str = ".",
        comment: str | None = ...,
        skipfooter: int = 0,
        convert_float: bool | None = ...,
        mangle_dupe_cols: bool = ...,
        storage_options: StorageOptions = ...,
    ) -> Validator: ...
    def read_feather(
        self,
        path: pydantic.FilePath | pydantic.AnyUrl,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        columns: Sequence[Hashable] | None = ...,
        use_threads: bool = ...,
        storage_options: StorageOptions = ...,
    ) -> Validator: ...
    def read_gbq(
        self,
        query: str,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        project_id: str | None = ...,
        index_col: str | None = ...,
        col_order: typing.List[str] | None = ...,
        reauth: bool = ...,
        auth_local_webserver: bool = ...,
        dialect: str | None = ...,
        location: str | None = ...,
        configuration: typing.Dict[str, typing.Any] | None = ...,
        credentials: typing.Any = ...,
        use_bqstorage_api: bool | None = ...,
        max_results: int | None = ...,
        progress_bar_type: str | None = ...,
    ) -> Validator: ...
    def read_hdf(
        self,
        path_or_buf: pd.HDFStore | os.PathLike | str,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        key: typing.Any = ...,
        mode: str = "r",
        errors: str = "strict",
        where: str | typing.List | None = ...,
        start: int | None = ...,
        stop: int | None = ...,
        columns: typing.List[str] | None = ...,
        iterator: bool = ...,
        chunksize: int | None = ...,
        kwargs: dict | None = ...,
    ) -> Validator: ...
    def read_html(
        self,
        io: os.PathLike | str,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        match: str | typing.Pattern = ".+",
        flavor: str | None = ...,
        header: int | Sequence[int] | None = ...,
        index_col: int | Sequence[int] | None = ...,
        skiprows: typing.Sequence[int] | int | None = ...,
        attrs: typing.Dict[str, str] | None = ...,
        parse_dates: bool = ...,
        thousands: str | None = ",",
        encoding: str | None = ...,
        decimal: str = ".",
        converters: typing.Dict | None = ...,
        na_values: Iterable[object] | None = ...,
        keep_default_na: bool = ...,
        displayed_only: bool = ...,
    ) -> Validator: ...
    def read_json(
        self,
        path_or_buf: pydantic.Json | pydantic.FilePath | pydantic.AnyUrl,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        orient: str | None = ...,
        dtype: dict | None = ...,
        convert_axes: typing.Any = ...,
        convert_dates: bool | typing.List[str] = ...,
        keep_default_dates: bool = ...,
        numpy: bool = ...,
        precise_float: bool = ...,
        date_unit: str | None = ...,
        encoding: str | None = ...,
        encoding_errors: str | None = "strict",
        lines: bool = ...,
        chunksize: int | None = ...,
        compression: CompressionOptions = "infer",
        nrows: int | None = ...,
        storage_options: StorageOptions = ...,
    ) -> Validator: ...
    def read_orc(
        self,
        path: pydantic.FilePath | pydantic.AnyUrl,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        columns: typing.List[str] | None = ...,
        kwargs: dict | None = ...,
    ) -> Validator: ...
    def read_parquet(
        self,
        path: pydantic.FilePath | pydantic.AnyUrl,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        engine: str = "auto",
        columns: typing.List[str] | None = ...,
        storage_options: StorageOptions = ...,
        use_nullable_dtypes: bool = ...,
        kwargs: dict | None = ...,
    ) -> Validator: ...
    def read_pickle(
        self,
        filepath_or_buffer: pydantic.FilePath | pydantic.AnyUrl,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        compression: CompressionOptions = "infer",
        storage_options: StorageOptions = ...,
    ) -> Validator: ...
    def read_sas(
        self,
        filepath_or_buffer: pydantic.FilePath | pydantic.AnyUrl,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        format: str | None = ...,
        index: Hashable | None = ...,
        encoding: str | None = ...,
        chunksize: int | None = ...,
        iterator: bool = ...,
        compression: CompressionOptions = "infer",
    ) -> Validator: ...
    def read_spss(
        self,
        path: pydantic.FilePath,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        usecols: int | str | typing.Sequence[int] | None = ...,
        convert_categoricals: bool = ...,
    ) -> Validator: ...
    def read_sql(
        self,
        sql: sqlalchemy.select | sqlalchemy.text | str,
        con: sqlalchemy.engine.Engine | sqlite3.Connection | str,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        index_col: str | typing.List[str] | None = ...,
        coerce_float: bool = ...,
        params: typing.Any = ...,
        parse_dates: typing.Any = ...,
        columns: typing.List[str] | None = ...,
        chunksize: int | None = ...,
    ) -> Validator: ...
    def read_sql_query(
        self,
        sql: sqlalchemy.select | sqlalchemy.text | str,
        con: sqlalchemy.engine.Engine | sqlite3.Connection | str,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        index_col: str | typing.List[str] | None = ...,
        coerce_float: bool = ...,
        params: typing.List[str] | typing.Dict[str, str] | None = ...,
        parse_dates: typing.List[str] | typing.Dict[str, str] | None = ...,
        chunksize: int | None = ...,
        dtype: dict | None = ...,
    ) -> Validator: ...
    def read_sql_table(
        self,
        table_name: str,
        con: sqlalchemy.engine.Engine | str,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        schema: str | None = ...,
        index_col: str | typing.List[str] | None = ...,
        coerce_float: bool = ...,
        parse_dates: typing.List[str] | typing.Dict[str, str] | None = ...,
        columns: typing.List[str] | None = ...,
        chunksize: int | None = ...,
    ) -> Validator: ...
    def read_stata(
        self,
        filepath_or_buffer: pydantic.FilePath | pydantic.AnyUrl,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        convert_dates: bool = ...,
        convert_categoricals: bool = ...,
        index_col: str | None = ...,
        convert_missing: bool = ...,
        preserve_dtypes: bool = ...,
        columns: Sequence[str] | None = ...,
        order_categoricals: bool = ...,
        chunksize: int | None = ...,
        iterator: bool = ...,
        compression: CompressionOptions = "infer",
        storage_options: StorageOptions = ...,
    ) -> Validator: ...
    def read_table(
        self,
        filepath_or_buffer: pydantic.FilePath | pydantic.AnyUrl,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        sep: str | None = ...,
        delimiter: str | None = ...,
        header: int | Sequence[int] | None | Literal["infer"] = "infer",
        names: Sequence[Hashable] | None = ...,
        index_col: IndexLabel | Literal[False] | None = ...,
        usecols: int | str | typing.Sequence[int] | None = ...,
        squeeze: bool | None = ...,
        prefix: str = ...,
        mangle_dupe_cols: bool = ...,
        dtype: dict | None = ...,
        engine: CSVEngine | None = ...,
        converters: typing.Any = ...,
        true_values: typing.Any = ...,
        false_values: typing.Any = ...,
        skipinitialspace: bool = ...,
        skiprows: typing.Sequence[int] | int | None = ...,
        skipfooter: int = 0,
        nrows: int | None = ...,
        na_values: typing.Any = ...,
        keep_default_na: bool = ...,
        na_filter: bool = ...,
        verbose: bool = ...,
        skip_blank_lines: bool = ...,
        parse_dates: typing.Any = ...,
        infer_datetime_format: bool = ...,
        keep_date_col: bool = ...,
        date_parser: typing.Any = ...,
        dayfirst: bool = ...,
        cache_dates: bool = ...,
        iterator: bool = ...,
        chunksize: int | None = ...,
        compression: CompressionOptions = "infer",
        thousands: str | None = ...,
        decimal: str = ".",
        lineterminator: str | None = ...,
        quotechar: str = '"',
        quoting: int = 0,
        doublequote: bool = ...,
        escapechar: str | None = ...,
        comment: str | None = ...,
        encoding: str | None = ...,
        encoding_errors: str | None = "strict",
        dialect: str | None = ...,
        error_bad_lines: bool | None = ...,
        warn_bad_lines: bool | None = ...,
        on_bad_lines: typing.Any = ...,
        delim_whitespace: typing.Any = ...,
        low_memory: typing.Any = ...,
        memory_map: bool = ...,
        float_precision: str | None = ...,
        storage_options: StorageOptions = ...,
    ) -> Validator: ...
    def read_xml(
        self,
        path_or_buffer: pydantic.FilePath | pydantic.AnyUrl,
        *,
        asset_name: str | None = ...,
        batch_metadata: BatchMetadata | None = ...,
        xpath: str = "./*",
        namespaces: typing.Dict[str, str] | None = ...,
        elems_only: bool = ...,
        attrs_only: bool = ...,
        names: Sequence[str] | None = ...,
        dtype: dict | None = ...,
        encoding: str | None = "utf-8",
        stylesheet: FilePath | None = ...,
        iterparse: typing.Dict[str, typing.List[str]] | None = ...,
        compression: CompressionOptions = "infer",
        storage_options: StorageOptions = ...,
    ) -> Validator: ...
