{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Data Validation Into Your Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep environment and logging\n",
    "\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "import great_expectations as ge\n",
    "import great_expectations.jupyter_ux\n",
    "import pandas as pd\n",
    "import uuid # used to generate run_id\n",
    "from datetime import datetime\n",
    "\n",
    "import tzlocal\n",
    "\n",
    "great_expectations.jupyter_ux.setup_notebook_logging()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is data validation integrated into a pipeline?\n",
    "\n",
    "To continue the example we used in the previous notebook, \n",
    "you created expectations for the data asset \"orders\". By doing this \n",
    "you defined what you expect a valid orders file to look like.\n",
    "\n",
    "Once your pipeline is deployed, it will process new orders files as they arrive.\n",
    "\n",
    "Just before calling the method that does the computation on a new file, call Great Expectations' \n",
    "validate method to make sure that the file meets your expectations about \n",
    "what a valid orders file should look like.\n",
    "If the file does not pass validation, you can decide what to do, e.g., stop the pipeline, since its output on invalid input cannot be guaranteed.\n",
    "\n",
    "\n",
    "To run validation you need 2 things: \n",
    "* Something to validate - in our case it is a file loaded into a Pandas data frame (or Spark Dataframe, if your pipeline is built on Spark)\n",
    "* Expectations to validate against - if you provide the name of the data asset for which you created expectations (\"orders\" in our example) to the validate method, Great Expectations will fetch the file with your expectations. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataContext object\n",
    "\n",
    "Just like in the previous notebook where you created expectations, we need to create a `DataContext` object that represents Great Expectations in your data pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context = ge.data_context.DataContext('../../', expectation_explorer=True)\n",
    "context = ge.data_context.DataContext('../../', expectation_explorer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the data asset name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.list_expectations_configs() # ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_asset_name = \"orders\" # TODO: replace with your value!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a file for validation\n",
    "\n",
    "set `file_path_to_validate` below to the full path of a file you want to validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_to_validate = # TODO: your file path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment the following if you are using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(file_path_to_validate)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment the following if you are using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# from great_expectations.dataset import PandasDataset, SqlAlchemyDataset, SparkDFDataset\n",
    "# spark = SparkSession.builder.getOrCreate()\n",
    "# df = SparkDFDataset(spark.read.csv(file_path_to_validate))\n",
    "# df.spark_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline run id\n",
    "\n",
    "Since your pipeline will validate batches before every run, we should pass run id to `validate`.\n",
    "\n",
    "In this notebook will just use a random UUID as run id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a run-id that GE will use to key shared parameters\n",
    "run_id = str(uuid.uuid1())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the file\n",
    "\n",
    "This is the \"workhorse\" method of Great Expectations. Call it in your pipeline code after loading the file and just before passing it to your computation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_result = ge.validate(df,\n",
    "          data_context=context, # Great Expectations context for your project\n",
    "          data_asset_name=data_asset_name, # data asset name that corresponds to a collection of expectations\n",
    "          run_id=run_id\n",
    "          )\n",
    "\n",
    "if validation_result[\"success\"]:\n",
    "    print(\"This file meets all expectations from a valid batch of {0:s}\".format(data_asset_name))\n",
    "else:\n",
    "    print(\"This file is not a valid batch of {0:s}\".format(data_asset_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is what a validation result looks like.\n",
    "\n",
    "The result object will have an element for each expectation defined for this data asset.\n",
    "If the batch did not pass an expectation, the element will have additional data (percentage of non-conforming records, examples of non-conforming values, etc.) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(validation_result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finishing touches - notifications and saving validation results and validated batches\n",
    "\n",
    "#### Notifications\n",
    "You want to be notified when the pipeline validated a batch, especially when the validation failed.\n",
    "\n",
    "Great Expectations provides a Slack integration. To enable this, uncomment `result_callback` section in your project's great-expectations.yml and enter your Slack webhook URL (see https://api.slack.com/incoming-webhooks).\n",
    "\n",
    "#### Saving validation results\n",
    "\n",
    "To enable the storing of validation results, uncomment the `result_store` section in your great_expectations.yml file. There are 2 options - local (see `filesystem` key) and on S3 (see `s3` key).\n",
    "\n",
    "This option will ensure that results of all validations are stored (both for batches that passed validation and those that did not meet our expectations).\n",
    "\n",
    "#### Saving failed batches\n",
    "\n",
    "When a batch fails validation (it does not pass all the expectations of the data asset), it is useful to save the batch along with the validation results for future review. You can enable this option in your project's great_expectations.yml file. There are 2 options - local (see `filesystem` key) and on S3 (see `s3` key).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
