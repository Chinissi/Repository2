{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Expectations End-to-End: Pipeline Portion\n",
    "\n",
    "This notebook demonstrates integration with a python-pandas pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import great_expectations as ge\n",
    "import great_expectations.jupyter_ux\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep environment\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import uuid # used to generate run_id\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import great_expectations as ge\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Prep logger\n",
    "import tzlocal\n",
    "\n",
    "def posix2local(timestamp, tz=tzlocal.get_localzone()):\n",
    "    \"\"\"Seconds since the epoch -> local time as an aware datetime object.\"\"\"\n",
    "    return datetime.fromtimestamp(timestamp, tz)\n",
    "\n",
    "class Formatter(logging.Formatter):\n",
    "    def converter(self, timestamp):\n",
    "        return posix2local(timestamp)\n",
    "\n",
    "    def formatTime(self, record, datefmt=None):\n",
    "        dt = self.converter(record.created)\n",
    "        if datefmt:\n",
    "            s = dt.strftime(datefmt)\n",
    "        else:\n",
    "            t = dt.strftime(self.default_time_format)\n",
    "            s = self.default_msec_format % (t, record.msecs)\n",
    "        return s\n",
    "\n",
    "logger = logging.getLogger('validation_notebook')\n",
    "chandler = logging.StreamHandler()\n",
    "chandler.setLevel(logging.DEBUG)\n",
    "# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "# chandler.setFormatter(formatter)\n",
    "chandler.setFormatter(Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\", \"%Y-%m-%dT%H:%M:%S%z\"))\n",
    "\n",
    "\n",
    "logger.addHandler(chandler)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Filter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a DataContext object\n",
    "\n",
    "First, we need to create a `DataContext` object - it represents Great Expectations in your data pipeline.\n",
    "We are passing '../../' to this object to let it know where to find its configuration. No need to modify this line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context = ge.data_context.DataContext('../../', expectation_explorer=True)\n",
    "context = ge.data_context.DataContext('../../', expectation_explorer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data source\n",
    "\n",
    "\n",
    "Data sources are locations where your pipeline reads its input data from. In our case, it is a directory on the local file system.\n",
    "\n",
    "When you ran `great_expectations init` in your project, you configured a data source of type \"pandas\" and gave it a name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Will be using this data source from your project's great_expectations.yml: <b>201810</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_source_name = great_expectations.jupyter_ux.set_data_source(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_source_name = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'201810'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_source_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'upkmemberkeys', '.DS_Store', 'provider', 'claim', 'providersupplemental', 'memberenrollment', 'member', 'claimcode'}\n"
     ]
    }
   ],
   "source": [
    "great_expectations.jupyter_ux.list_available_data_asset_names(context, data_source_name=data_source_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP\n",
    "\n",
    "When you were creating expectations \n",
    "\n",
    "some continuous process that produces them... \n",
    "\n",
    "a pipeline is running \n",
    "\n",
    "orders \n",
    "\n",
    "a new file appears periodically. The file contains a new batch of order records\n",
    "\n",
    "What does a valid batch of orders look like? What can my code assume about it?\n",
    "\n",
    "You pointed GE at a directory that contained several files representing batches of this data asset\n",
    "\n",
    "Let's assume that your pipeline processes new files (new batches) when they arrive.\n",
    "\n",
    "The way to integrate validation into your pipeline \n",
    "\n",
    "\n",
    "you have a node in your DAG \n",
    "When you were implementing its logic you made some assumptions about its input data\n",
    "(e.g., I assume that values in \"date_of_birth\" column are date sttrings in 'YYYY-MM-DD' format,\n",
    "they are never null and they are in a reasonable range representing people of working age).\n",
    "You encoded these assumptions as expectations.\n",
    "This allows you not to complicate your code with checks of validity \n",
    "and you want to protect it from processing data that it was not designed to deal with.\n",
    "\n",
    "When a new batch of orders (in a form of a CSV file) arrives, \n",
    "Detecting that the file is available and reading it into memory is something you already do.\n",
    "\n",
    "you read the file into a Pandas data frame.\n",
    "Before passing the data frame to your node, call Great Expectations to validate it.\n",
    "If the data does not pass the validation, it means that the data violates assumptions made \n",
    "by the code. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_to_validate = '/Users/eugenemandel/project_data/clarify_payer/claim_data/ability_payer/staging/201810/claimcode/000000_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path_to_validate, sep=\"|\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------+----------+---+---+------+---+----------+\n",
      "|        _c0|      _c1|       _c2|       _c3|_c4|_c5|   _c6|_c7|       _c8|\n",
      "+-----------+---------+----------+----------+---+---+------+---+----------+\n",
      "|37359363450|217767923|2016-04-21|2016-04-21|  5|  0| C2617|  0|2018-10-25|\n",
      "|37359363450|217767923|2016-04-21|2016-04-21| 16|  0|  0278|  0|2018-10-25|\n",
      "|37359363450|217767923|2016-04-21|2016-04-21| 13|  1|   131|  1|2018-10-25|\n",
      "|37359363450|217767923|2016-04-21|2016-04-21| 13|  0|   137|  0|2018-10-25|\n",
      "|37359363450|217767923|2016-04-21|2016-04-21| 10|  0|    22|  0|2018-10-25|\n",
      "|37359363450|217767923|2016-04-21|2016-04-21| 11|  1|    OA|  1|2018-10-25|\n",
      "|37359363450|217767923|2016-04-21|2016-04-21| 11|  0|    OT|  1|2018-10-25|\n",
      "|37359363450|217767923|2016-04-21|2016-04-21| 17|  5|Z87891|  0|2018-10-25|\n",
      "|37359363450|217767923|2016-04-21|2016-04-21| 17|  2|   I10|  0|2018-10-25|\n",
      "|37359363450|217767923|2016-04-21|2016-04-21| 17|  0|  N200|  0|2018-10-25|\n",
      "|37359363450|217767923|2016-04-21|2016-04-21| 17|  3|  N201|  0|2018-10-25|\n",
      "|37359363450|217767923|2016-04-21|2016-04-21| 17|  4|Z79899|  0|2018-10-25|\n",
      "|37359363450|217767923|2016-04-21|2016-04-21| 17|  1|  E785|  0|2018-10-25|\n",
      "|37359363958|232509363|2016-06-22|2016-06-22| 17|  0|Z00129|  0|2018-10-25|\n",
      "|37359363958|232509363|2016-06-22|2016-06-22| 17|  1|  E039|  0|2018-10-25|\n",
      "|37359363958|232509363|2016-06-22|2016-06-22| 11|  0|    OC|  1|2018-10-25|\n",
      "|37359363958|232509363|2016-06-22|2016-06-22| 10|  0|    11|  0|2018-10-25|\n",
      "|37359363958|232509363|2016-06-22|2016-06-22|  3|  0| 99384|  0|2018-10-25|\n",
      "|37359364428|233828901|2016-06-09|2016-06-09|  3|  0| 88372|  0|2018-10-25|\n",
      "|37359364428|233828901|2016-06-09|2016-06-09| 10|  0|    11|  0|2018-10-25|\n",
      "+-----------+---------+----------+----------+---+---+------+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from great_expectations.dataset import PandasDataset, SqlAlchemyDataset, SparkDFDataset\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = SparkDFDataset(spark.read.csv(file_path_to_validate, sep=\"|\"))\n",
    "df.spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Pipeline Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a run-id that GE will use to key shared parameters\n",
    "run_id = str(uuid.uuid1())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = ge.validate(df,\n",
    "#                   data_context=context,\n",
    "#                   data_asset_name='claimcode',\n",
    "# #                   run_id=run_id,\n",
    "# #                   only_return_failures=False,\n",
    "# #                   save_dataset_on_failure=dataset_s3,\n",
    "# #                   result_store=result_s3,\n",
    "# #                   result_callback=slack_callback,\n",
    "#                   )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # results = ge.validate(df,\n",
    "# #                   data_context=pipeline_data_context,\n",
    "# #                   data_asset_name=\"\",\n",
    "# #                   run_id=run_id,\n",
    "# #                   only_return_failures=False,\n",
    "# #                   save_dataset_on_failure=dataset_s3,\n",
    "# #                   result_store=result_s3,\n",
    "# #                   result_callback=slack_callback,\n",
    "# #                   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['5'] = df['5'] + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c1440e79d14f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mdata_asset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'claimcode'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                   \u001b[0monly_return_failures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#                   save_dataset_on_failure=dataset_s3,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#                   result_store=result_s3,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/great_expectations/great_expectations/util.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(data_asset, expectations_config, data_asset_name, data_context, data_asset_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;31m# and no conversion is needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_asset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata_asset_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata_asset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpectations_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpectations_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdata_asset_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# Guess the GE data_asset_type based on the type of the data_asset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/great_expectations/great_expectations/data_asset/data_asset.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, expectations_config, run_id, data_context, evaluation_parameters, catch_exceptions, result_format, only_return_failures)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_validation_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate__data_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/great_expectations/great_expectations/data_context/data_context.py\u001b[0m in \u001b[0;36mregister_validation_results\u001b[0;34m(self, run_id, validation_results, data_asset)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                 with open(os.path.join(self.context_root_directory, \"great_expectations\", result_store[\"filesystem\"][\"base_directory\"],\n\u001b[0;32m--> 386\u001b[0;31m                                        run_id, data_asset_name + \".json\"), \"w\") as outfile:\n\u001b[0m\u001b[1;32m    387\u001b[0m                     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_store\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"s3\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult_store\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "ge.validate(df,\n",
    "                  data_context=context,\n",
    "                  data_asset_name='claimcode',\n",
    "                  run_id=run_id,\n",
    "                  only_return_failures=False,\n",
    "#                   save_dataset_on_failure=dataset_s3,\n",
    "#                   result_store=result_s3,\n",
    "#                   result_callback=slack_callback,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2fc10bda-87de-11e9-bc40-645aedea36fd'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more ../uncommitted/validations/72bfba34-87b7-11e9-ac4c-645aedea36fd/claimcode.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -al  ../uncommitted/snapshots/72bfba34-87b7-11e9-ac4c-645aedea36fd/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GE: Validate prior to our transform\n",
    "data_asset_name = 'source_diabetes_data'\n",
    "logger.info(\"Validating dataset %s\" % data_asset_name)\n",
    "config = pipeline_data_context.get_data_asset_config(data_asset_name)\n",
    "\n",
    "bucket = 'dev.maglev-design.projects.superconductivehealth.priv'\n",
    "result_key = 'diabetes_pipeline/' + run_id + '/validation_results/' + data_asset_name + '.json'\n",
    "failed_dataset_key = 'diabetes_pipeline/' + run_id + '/data_assets/' + data_asset_name + '.csv'\n",
    "\n",
    "result_s3 = s3.Object(bucket, result_key)\n",
    "dataset_s3 = s3.Object(bucket, failed_dataset_key)\n",
    "\n",
    "logger.debug(\"Storing validation results to s3. bucket: %s; key: %s\" % (bucket, result_key))\n",
    "results = ge.validate(df,\n",
    "                  expectations_config=config,\n",
    "                  data_asset_type=DiagnosticCodesDataset,\n",
    "                  run_id=run_id,\n",
    "                  only_return_failures=False,\n",
    "                  save_dataset_on_failure=dataset_s3,\n",
    "                  result_store=result_s3,\n",
    "                  result_callback=slack_callback,\n",
    "                  data_context=pipeline_data_context)\n",
    "\n",
    "\n",
    "if results[\"success\"] != True:\n",
    "    logger.warn(\"Validation included failures! Check results at \" + results[\"meta\"][\"result_reference\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete pipeline\n",
    "logger.info(\"Storing output data to %s\" % ('./output/' + run_id + '/' + data_asset_name + '.csv'))\n",
    "os.makedirs(\"./output/\" + run_id, exist_ok=True)\n",
    "df.to_csv('./output/' + run_id + '/' + data_asset_name + '.csv')\n",
    "del df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
