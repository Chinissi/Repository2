{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Great Expectations for DBT Model Development\n",
    "\n",
    "[dbt (data build tool)](https://www.getdbt.com) is an incredible tool that makes building SQL transformation pipelines a dream. In dbt, each `.sql` file is a **model**. As these models are developed, you can encode assumptions about input and output datasets as **expectations**.\n",
    "\n",
    "This has the following benefits:\n",
    "\n",
    "1. These are machine verifiable and can be used to monitor data flowing through your pipelines.\n",
    "2. These eliminate poisonous implicit assumptions that cause data engineers re-work and waste time - \"How do we define visits?\"\n",
    "3. These **will eventually** be easy to edit.\n",
    "4. These **will eventually** be easy to reason about visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import great_expectations as ge\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import random\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up DBT Tools\n",
    "\n",
    "This is a helper class that makes using great expectations with dbt easy!\n",
    "\n",
    "You'll need:\n",
    "- your dbt `profile name`\n",
    "- your dbt `target`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = \"superconductive\"\n",
    "target = \"rds\"\n",
    "\n",
    "dbt_tools = ge.DBTTools(profile, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a DataContext\n",
    "\n",
    "A great expectations `DataContext` represents the collection of data asset specifications in this project.\n",
    "\n",
    "You'll need:\n",
    "- the directory where you ran `great_expectations init` (where the .great_expectations.yml file is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_data_context = ge.data_context.DataContext('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data asset configs\n",
    "\n",
    "**Data asset configs** represent a type of data asset that is specified by a collection of expectations. We'll make one for the input and the output datasets. This allows us to protect our model from dirty data and have a downstream data contract.\n",
    "\n",
    "In a dbt pipeline we give these configuration files the same name as the dbt models by convention.\n",
    "\n",
    "If the data asset config for this name exists in the project, the method will load it from the file. The configuration files are stored in `great_expectations/data_asset_configurations` folder in the current project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_encounters_config = pipeline_data_context.get_data_asset_config('base/base_encounters')\n",
    "base_encounters_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data asset configs (expectation collections) for the input and output datasets are empty. We will load result sets for these modules and create some expectations for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = dbt_tools.get_sqlalchemy_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads the result set of the schedule_appointments model into schedule_appointments data asset config.\n",
    "\n",
    "We can call GE's `expect_*` methods on this dataset. This will both test if the dataset conforms to an expectation and will add this expectation to the config, if it does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO this feels really clunky\n",
    "\n",
    "- Don't make the user supply a guid for `table_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = dbt_tools.get_model_compiled_sql('base/base_schedule_appointment')\n",
    "\n",
    "df_base_encounters = ge.dataset.SqlAlchemyDataset(engine=engine, custom_sql=query_str)\n",
    "\n",
    "df_base_encounters._initialize_expectations(config=base_encounters_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we extract appointment's date from start_date column, can we assume that a non-empty value is always present?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_scheduleappointment.expect_column_values_to_not_be_null('start_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No! Good to know. We will add a where clause to our every_visit_per_day's SQL to filter the empties out. Also, let's record the fact that we expect close to half of scheduleappopintments records to not have a value. If the percentage is exceeded, valiation will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_scheduleappointment.expect_column_values_to_not_be_null('start_date', mostly=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can we assume that (the non-empty) start_date values will be in a reasonable range (few recent years) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_scheduleappointment.expect_column_values_to_be_between('start_date', min_value='2010-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No! A small percentage of values are earlier that would make sense. Just like the in the \"null\" case earlier, let's add a where clause to every_visit_per_day's SQL and add an expectation on the input dataset to say that we do expect some nonsensical dates, but only a very small percentage (up to 1%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_scheduleappointment.expect_column_values_to_be_between('start_date', min_value='2010-01-01', mostly=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We assume that records in scheduleappointments table represents one day appointments, not hospitalizations or any other multi-day treatments. Actually, can we assume that? Let's check... \n",
    "\n",
    "#### In this case the easiest way to add this expectation is to add a computed column to the input model's SQL and add an expectation of this column values range. This is a pattern that is worth noticing - often it is easier to add an expectation from the standard library to a computed column than a custom expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_scheduleappointment.expect_column_values_to_be_between('scheduled_duration_sec', min_value=10, max_value=86400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our assumption is *almost* correct - there is a very small number of exceptions. In this case let's not even modify every_visit_per_day's SQL. Let's create an expectation on the input dataset that the rate of exceptions is under 1%. If it every changes, validation will fail and we will be notified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_scheduleappointment.expect_column_values_to_be_between('scheduled_duration_sec', min_value=10, max_value=86400, mostly=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We probably keep adding expectations to the input dataset, but for the demo purpose let's stop here and save the expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_scheduleappointment.get_expectations_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO strip out `/` from json names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_data_context.save_data_asset_config(df_base_scheduleappointment.get_expectations_config())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previously we encoded our assumptions about the input dataset as expectations - this protects us from the risk coming from upstream. Now let's be nice to our the downstream models that consume the output of the every_visit_per_day model. We will encode our assumptions on our model's result set. This advertises to the downstream consumers what they can expect from us - a data contract of sorts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the result set of every_visit_per_day model into GE \n",
    "\n",
    "query_str = dbt_tools.get_model_compiled_sql('schedule_appointments')\n",
    "\n",
    "df_every_visit_per_day = ge.dataset.SqlAlchemyDataset(engine=engine, table_name=\"tmp{0:d}\".format(random.randint(1,100000)), custom_sql=query_str)\n",
    "df_every_visit_per_day._initialize_expectations(config=every_visit_per_day_dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we filtered out empty start_date values, we can confidently advertise this fact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_every_visit_per_day.expect_column_values_to_not_be_null('start_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"success: True\" means that the result set conforms to our expectations - good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same logic applies to the range of values of start_date, since we filtered the unreasonably old ones in our SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_every_visit_per_day.expect_column_values_to_be_between('start_date', min_value='2010-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We carry the expectation of no multi day appointments (with no more than 1% exceptions) from the input dataset (since we are not filtering them out in our SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_every_visit_per_day.expect_column_values_to_be_between('scheduled_duration_sec', min_value=10, max_value=86400, mostly=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are there any duplicated in the input dataset and, if yes, should we dedup them in every_visit_per_day's SQL?\n",
    "\n",
    "#### This requires us to hypothesize about what might be viewed as a unique key in scheduleappointment. Let's say that the combination of start_date, office id, patient id and the provider id is a good candidate. Let's add this is a column to our model: `concat(sa.start_date, '__', office_id, '__', user_id_patient, '__', user_id_to_see) as appointment_key`.\n",
    "\n",
    "#### Yet again, this is an example of adding a computed column so that we can reason on it using expectations. Check if we can assume this value to be unique in our result set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_every_visit_per_day.expect_column_values_to_be_unique('appointment_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is mostly unique - less than 2% exceptions. It is possible that we will have to deal with deduplication before deployment, but for now let's just encode this assumption as an expectation so that we don't forget it and so that other stake holders can see it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_every_visit_per_day.expect_column_values_to_be_unique('appointment_key', mostly=0.98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is another example of encoding our assumption that would not be visible in the SQL source itself - scheduleappointment has `active` column that takes True and False values. We are not sure what it means - should \"inactive\" appointments be filtered out? Let's defer this decision and encode the assumption that the value of active is not important as an expectation on our output dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_every_visit_per_day.expect_column_values_to_be_in_set('active', ['t'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's stop here for now and save the expectations on the output set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_every_visit_per_day.get_expectations_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_data_context.save_data_asset_config(df_every_visit_per_day.get_expectations_config())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The expectation collections for the two datasets are saved into JSON files in great_expectations/data_asset_configurations folder in the current project - let's commit them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
