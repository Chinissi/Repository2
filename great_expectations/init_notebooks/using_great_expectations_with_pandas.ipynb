{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Expectations on \n",
    "\n",
    "As your data products and models are developed, you can encode assumptions about input and output datasets as **expectations**.\n",
    "\n",
    "Using that workflow provides the following benefits:\n",
    "\n",
    "1. These are machine verifiable and can be used to monitor data flowing through your pipelines.\n",
    "2. These eliminate poisonous implicit assumptions that cause data engineers re-work and waste time - \"How do we define visits?\"\n",
    "3. These **will eventually** be easy to edit.\n",
    "4. These **will eventually** be easy to reason about visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to load spark context; install optional spark dependency for support.\n",
      "Unable to load spark context; install optional spark dependency for support.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import great_expectations as ge\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a DataContext\n",
    "\n",
    "A great expectations `DataContext` represents the collection of data asset specifications in this project.\n",
    "\n",
    "You'll need:\n",
    "- the directory where you ran `great_expectations init` (where the .great_expectations.yml file is).\n",
    "- dbt profile and target information in the datasources section of your great_expectations configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context = ge.data_context.DataContext('../../', expectation_explorer=True)\n",
    "context = ge.data_context.DataContext('../../', expectation_explorer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a Dataset\n",
    "\n",
    "Using the data context, provide the name of the datasource configured in your project config (\"dbt\" in this case), and the name of the dbt model to which to connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = context.get_data_asset(\"mycsvfile\", data_asset_name=\"titanic_input_file\", file_path=\"tutorial_data/Titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.get_expectations_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Expectations\n",
    "\n",
    "As you develop your code\n",
    "\n",
    "state an assumption your code makes about its input data\n",
    "\n",
    "Check on the available data sample if you can expect this assumption to be true\n",
    "\n",
    "If the available data sample violates this assumption, decide how your code should deal with the violations\n",
    "\n",
    "Update your assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we assume that \"male\" and \"female\" are the only values we will see in \"Sex\" column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.expect_column_values_to_be_in_set('Sex', ['female', 'male'], include_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yes. Let's keep this expectation - if our code encounters input data that does not conform to it, we want to know about"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we assume that all people in our input data have non-empty value in \"Age\" column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': False,\n",
       " 'result': {'element_count': 1313,\n",
       "  'missing_count': 0,\n",
       "  'missing_percent': 0.0,\n",
       "  'unexpected_count': 557,\n",
       "  'unexpected_percent': 0.4242193450114242,\n",
       "  'partial_unexpected_list': []}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.expect_column_values_to_not_be_null('Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No. We will have to adjust our code to deal with nulls in this column. However, let's make sure that if in future our code encounters input data where there more nulls than we expect, we will be notified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'result': {'element_count': 1313,\n",
       "  'missing_count': 0,\n",
       "  'missing_percent': 0.0,\n",
       "  'unexpected_count': 557,\n",
       "  'unexpected_percent': 0.4242193450114242,\n",
       "  'partial_unexpected_list': []}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.expect_column_values_to_not_be_null('Age', mostly=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we assume that all \"Age\" column values are in a reasonable range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.expect_column_value_lengths_to_be_between('Age', min_value=0, max_value=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yes. Great - let's keep this expectation. Our code can assume that this is true. If in future we will see input data that violates this expectation, our validation will catch it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's review the expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: get_expectations_config discarded\n",
      "\t1 failing expectations\n",
      "\t1 result_format kwargs\n",
      "\t0 include_configs kwargs\n",
      "\t0 catch_exceptions kwargs\n",
      "If you wish to change this behavior, please set discard_failed_expectations, discard_result_format_kwargs, discard_include_configs_kwargs, and discard_catch_exceptions_kwargs appropirately.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data_asset_name': 'None',\n",
       " 'meta': {'great_expectations.__version__': '0.6.0__develop__sch_internal'},\n",
       " 'expectations': [{'expectation_type': 'expect_column_values_to_not_be_null',\n",
       "   'kwargs': {'column': 'Age', 'mostly': 0.5}}],\n",
       " 'data_asset_type': 'Dataset'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.get_expectations_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and save them. Expectations for \"titanic_input_file\" will be saved in a JSON file in great_expectations/data_asset_configurations directory. We will load this file when we need to validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_every_visit_per_day.save_expectations_config()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
