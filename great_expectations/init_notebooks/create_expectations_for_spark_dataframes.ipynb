{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import great_expectations as ge\n",
    "import great_expectations.jupyter_ux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author Expectations For The CSV Files You Read Into Spark Dataframes\n",
    "\n",
    "When you develop your data pipeline code, you make some assumptions about what valid input data looks like.\n",
    "You can encode these assumptions as *expectations* (e.g., \"column X should not have more than 5% null values\").\n",
    "\n",
    "Once you deploy your code in production, Great Expectations will validate new data and check if it conforms to the assumptions your code makes.\n",
    "\n",
    "This way you can stop data that your code does not know how to deal with from being processed, thus avoiding the \"garbage in, garbage out\" problem.\n",
    "\n",
    "First, you have to author your expectations for every type of file your code processes.\n",
    "\n",
    "In this notebook you can create expectations for the CSV files that you will load into Spark Dataframes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a DataContext object\n",
    "\n",
    "First, we need to create a `DataContext` object - it represents Great Expectations in your data pipeline.\n",
    "We are passing '../../' to this object to let it know where to find its configuration. No need to modify this line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context = ge.data_context.DataContext('../../', expectation_explorer=True)\n",
    "context = ge.data_context.DataContext('../../', expectation_explorer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data source\n",
    "\n",
    "\n",
    "Data sources are locations where your pipeline reads its input data from. In our case, it is a directory on the local file system.\n",
    "\n",
    "When you ran `great_expectations init` in your project, you configured a data source of type \"spark\" and gave it a name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Will be using this spark data source from your project's great_expectations.yml: <b>201810</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_source_name = great_expectations.jupyter_ux.set_data_source(context, 'spark')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_source_name = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'201810'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_source_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Great Expectations we use the name \"data asset\" for each \"type\" of files.\n",
    "\n",
    "Let's say that your Spark data pipeline processes CSV files in `/data/my_input_directory` directory on the filesystem.\n",
    "CSV files that contain orders lines are deposited in the subdirectory `orders` and the ones contain cancellations lines in `cancellations`. Each CSV file has date and/or sequence number in its name.\n",
    "\n",
    "Following this example, this directory will looks like this:\n",
    "\n",
    "    my_input_directory\n",
    "        ├── orders\n",
    "        |   └── orders_20190101_1.csv        \n",
    "        |   └── orders_20190102_1.csv        \n",
    "        |   └── orders_20190103_1.csv        \n",
    "        ├── cancellations\n",
    "        |   └── cancellations_20190101_1.csv        \n",
    "        |   └── cancellations_20190102_1.csv        \n",
    "        |   └── cancellations_20190103_1.csv        \n",
    "\n",
    "In this example there are 2 data assets: \"orders\" and \"cancellations\". You can create expectations about these types.\n",
    "\n",
    "In order to create expectations about a data asset (e.g., orders), you will need to load one of the files of this type\n",
    "into Great Expectations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'member', 'providersupplemental', 'claimcode', 'memberenrollment', 'upkmemberkeys', 'claim', 'provider', '.DS_Store'}\n"
     ]
    }
   ],
   "source": [
    "great_expectations.jupyter_ux.list_available_data_asset_names(context, data_source_name=data_source_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pick one of the data asset names above and use as the value of data_asset_name argument below.\n",
    "\n",
    "**Note: If you need to pass options to Spark reader (e.g., delimiter, header, etc), you can add them as arguments in the method call below. Once you have all your options, add them to the config of this datasource in great_expectations.yml under \"reader_options\" key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "../../project_data/clarify_payer/claim_data/ability_payer/staging/201810/orders",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5b33ead8c53e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data_asset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_source_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_asset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"orders\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/great_expectations/great_expectations/data_context/base.py\u001b[0m in \u001b[0;36mget_data_asset\u001b[0;34m(self, datasource_name, data_asset_name, batch_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't find datasource {0:s} in the config - please check your great_expectations.yml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mdata_asset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data_asset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_asset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;31m# data_asset._initialize_expectations(self.get_data_asset_config(data_asset_name))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata_asset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/great_expectations/great_expectations/data_context/datasource/datasource.py\u001b[0m in \u001b[0;36mget_data_asset\u001b[0;34m(self, data_asset_name, batch_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0mbatch_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myield_batch_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_asset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No generator or batch_kwargs available to provide a dataset.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/great_expectations/great_expectations/data_context/datasource/batch_generator.py\u001b[0m in \u001b[0;36myield_batch_kwargs\u001b[0;34m(self, data_asset_name)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0myield_batch_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_asset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_asset_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_asset_iterators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_asset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mdata_asset_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_asset_iterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_asset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/great_expectations/great_expectations/data_context/datasource/batch_generator.py\u001b[0m in \u001b[0;36mreset_iterator\u001b[0;34m(self, data_asset_name)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_asset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_asset_iterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_asset_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_asset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_asset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/great_expectations/great_expectations/data_context/datasource/filesystem_path_generator.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self, data_asset_name)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 ])\n\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_asset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Removed to support python2 (no scandir; listdir instead)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: ../../project_data/clarify_payer/claim_data/ability_payer/staging/201810/orders"
     ]
    }
   ],
   "source": [
    "df = context.get_data_asset(data_source_name, data_asset_name=\"orders\")\n",
    "df.spark_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call in the cell above loaded one of the batches of this data asset. \n",
    "When working with files, batch corresponds to one file\n",
    "You can read more on this here:\n",
    "https://great-expectations.readthedocs.io/en/latest/what_are_batches.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/Users/eugenemandel/projects/forum-edw/../../project_data/clarify_payer/claim_data/ability_payer/staging/201810/claimcode/000000_0'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is how you can see which file was loaded\n",
    "df._batch_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author Expectations\n",
    "\n",
    "Now that you have one of the files loaded, you can call expect* methods on the dataframe in order to check\n",
    "if you can make an assumption about the data.\n",
    "\n",
    "For example, to check if you can expect values in column \"order_date\" to never be empty, call: `df.expect_column_values_to_not_be_null('order_date')`\n",
    "\n",
    "### How do I know which types of expectations I can add?\n",
    "* *Tab-complete* this statement, and add an expectation of your own; copy the cell to add more\n",
    "* In jupyter, you can also use *shift-tab* to see the docstring for each expectation, to see what parameters it takes and get more information about the expectation.\n",
    "* Here is a glossary of expectations you can add:\n",
    "https://great-expectations.readthedocs.io/en/latest/glossary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'result': {'element_count': 26427155,\n",
       "  'missing_count': 0,\n",
       "  'missing_percent': 0.0,\n",
       "  'unexpected_count': 0,\n",
       "  'unexpected_percent': 0.0,\n",
       "  'partial_unexpected_list': []}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example:\n",
    "\n",
    "column_name = df.spark_df.columns[0]\n",
    "df.expect_column_values_to_not_be_null(column_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's review the expectations.\n",
    "\n",
    "Expectations that were true on this data sample were added. To view all the expectations you added so far about this type of files, do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: get_expectations_config discarded\n",
      "\t0 failing expectations\n",
      "\t1 result_format kwargs\n",
      "\t0 include_configs kwargs\n",
      "\t0 catch_exceptions kwargs\n",
      "If you wish to change this behavior, please set discard_failed_expectations, discard_result_format_kwargs, discard_include_configs_kwargs, and discard_catch_exceptions_kwargs appropirately.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data_asset_name': 'claimcode',\n",
       " 'meta': {'great_expectations.__version__': '0.6.1__develop__sch_internal'},\n",
       " 'expectations': [{'expectation_type': 'expect_column_values_to_not_be_null',\n",
       "   'kwargs': {'column': '_c0'}}],\n",
       " 'data_asset_type': 'Dataset'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.get_expectations_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's save the expectations about this type of files. Expectations for \"orders\" in our example will be saved in a JSON file in great_expectations/data_asset_configurations directory. We will load this file when we need to validate.\n",
    "\n",
    "\n",
    "      your_project_root\n",
    "        ├── great_expectations\n",
    "        |   └── expectations\n",
    "        |     └── orders.json        \n",
    "        |     └── cancellations.json        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: get_expectations_config discarded\n",
      "\t0 failing expectations\n",
      "\t1 result_format kwargs\n",
      "\t0 include_configs kwargs\n",
      "\t0 catch_exceptions kwargs\n",
      "If you wish to change this behavior, please set discard_failed_expectations, discard_result_format_kwargs, discard_include_configs_kwargs, and discard_catch_exceptions_kwargs appropirately.\n"
     ]
    }
   ],
   "source": [
    "df.save_expectations_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that you created and saved expectations for at least one of the types of CSV files your data pipeline processes, we will show you how to set up validation - the process of checking if new files of this type conform to your expectations before they are processed by your pipeline's code. \n",
    "\n",
    "Check out the notebook \"validate_csv_files.ipynb\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
