{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import great_expectations as ge\n",
    "import great_expectations.jupyter_ux\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author Expectations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('_0tG7ACNU4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a DataContext object\n",
    "\n",
    "https://great-expectations.readthedocs.io/en/latest/create_expectations_tutorial.html#get_datacontext_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ge.data_context.DataContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's list data assets in your project\n",
    "\n",
    "https://great-expectations.readthedocs.io/en/latest/create_expectations_tutorial.html#data_assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "great_expectations.jupyter_ux.list_available_data_asset_names(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pick one of the data asset names above and use as the value of data_asset_name argument below.\n",
    "\n",
    "https://great-expectations.readthedocs.io/en/latest/create_expectations_tutorial.html#get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = context.get_batch('!!!USE ONE OF THE DATA ASSET NAMES FROM ABOVE!!!/my_suite')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: If you need to pass options to read your data (e.g., separators, header, etc), see this:\n",
    "https://great-expectations.readthedocs.io/en/latest/create_expectations_tutorial.html#how_to_control_data_reading_options\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call in the cell above loaded one of the batches of this data asset. \n",
    "When working with files, batch corresponds to one file\n",
    "You can read more on this here:\n",
    "https://great-expectations.readthedocs.io/en/latest/what_are_batches.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how you can see which file was loaded\n",
    "df._batch_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author Expectations\n",
    "\n",
    "Now that you have one of the data batches loaded, you can call expect* methods on the dataframe in order to check\n",
    "if you can make an assumption about the data.\n",
    "\n",
    "For example, to check if you can expect values in column \"order_date\" to never be empty, call: `df.expect_column_values_to_not_be_null('order_date')`\n",
    "\n",
    "### How do I know which types of expectations I can add?\n",
    "* *Tab-complete* this statement, and add an expectation of your own; copy the cell to add more\n",
    "* In jupyter, you can also use *shift-tab* to see the docstring for each expectation, to see what parameters it takes and get more information about the expectation.\n",
    "* Here is a glossary of expectations you can add:\n",
    "https://great-expectations.readthedocs.io/en/latest/glossary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example:\n",
    "\n",
    "column_name = df.columns[0]\n",
    "df.expect_column_values_to_not_be_null(column_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more expectations here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more expectations here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more expectations here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's review the expectations.\n",
    "\n",
    "Expectations that were true on this data batch were added. To view all the expectations you added so far about this data asset, do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.get_expectation_suite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.save_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You created and saved expectations for at least one of the data assets.\n",
    "\n",
    "### We will show you how to set up validation - the process of checking if new files of this type conform to your expectations before they are processed by your pipeline's code. \n",
    "\n",
    "### Go to [integrate_validation_into_pipeline.ipynb](integrate_validation_into_pipeline.ipynb) to proceed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
