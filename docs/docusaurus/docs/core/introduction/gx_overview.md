---
title: Great Expectations overview
---

This overview is for new users of the Great Expectations (GX) and those looking for an improved understanding of GX components and primary workflows. It is an ideal place to start before exploring more advanced GX topics found in the GX documentation.

## GX Core components and workflows

GX is a framework for describing data using expressive tests and then validating that the data meets test criteria. GX Core is a Python library that provides a programmatic interface to building and running data validation workflows using GX.

GX Core is versatile and supports a variety of workflows. It can be used for interactive, exploratory data validation as well as data validation within production deployments.

**GX components** are Python classes that represent your data and data validation entities.

**GX workflows** are programmatically defined data validation processes. GX workflows are built using GX components.

## The pattern of a GX workflow

All GX workflows share a common pattern:

1. Set up a GX environment
2. Connect to data
3. Define Expectations
4. Run Validations

At each workflow step, different GX components are defined and used. This section introduces the key GX components required to create a data validation workflow.

![GX workflow pattern with related GX components](./overview_images/gx_workflow_steps_and_components.png)

### Set up a GX environment

A **Data Context** manages the settings and metadata for a GX workflow. In GX Core, the Data Context is a Python object that serves as the entrypoint for the [GX Python API](/reference/). You use the Data Context to define and run a GX workflow; the Data Context provides access to the configurations, metadata, and actions of your GX workflow components and the results of data validations.

All GX workflows start with the creation of a Data Context.

For more information on the types of Data Context, see [Create a Data Context](/core/set_up_a_gx_environment/create_a_data_context.md).

### Connect to data

A **Data Source** is the GX representation of a data store. The Data Source tells GX how to connect to your data, and supports connection to different types of data stores, including databases, schemas, and data files in cloud object storage.

A **Data Asset** is a collection of records within a Data Source. A useful analogy is: if a Data Source is a relational database, then a Data Asset is a table within that database, or the results of a select query on a table within that database.

A **Batch Definition** tells GX how to organize the records within a Data Asset. The Batch Definition Python object enables you to retrieve a **Batch**, or collection of records from a Data Asset, for validation at runtime. A Data Asset can be validated as a single Batch, or partitioned into multiple Batches for separate validations.

For more information on connecting to data, see [Connect to data](/core/connect_to_data/).

### Define Expectations

An **Expectation** is a verifiable assertion about data. Similar to assertions in traditional Python unit tests, Expectations provide a flexible, declarative language for describing expected behaviors. An Expectation can be used to validate a Batch of data.

For a full list of available Expectations, see [the Expectation Gallery](https://greatexpectations.io/expectations/).

An **Expectation Suite** is a collection of Expectations. Expectation Suites can be used to validate a Batch of data using multiple Expectations, streamlining the validation process. You can define multiple Expectation Suites for the same data to cover different use cases, and you can apply the same Expectation Suite to different Batches.

For more information defining Expectations and creating Expectation Suites, see [Define Expectations](/core/define_expectations/).

### Run Validations

A **Validation Definition** explicitly associates a Batch Definition to an Expectation Suite, defining what data should be validated against which Expectations.

A **Validation Result** is returned by GX after data validation. The Validation Results tell you how your data corresponds to what you expected of it.

A **Checkpoint** is the primary means for validating data in a production deployment of GX. Checkpoints enable you to run a list of Validation Definitions with shared parameters. Checkpoints can be configured to run Actions, and can pass Validation Results to a list of predefined Actions for processing.

**Actions** provide a mechanism to integrate Checkpoints into your data pipeline infrastructure by automatically processing Validation Results. Typical use cases include sending email alerts, Slack messages, or custom notifications based on the result of data validation.

**Data Docs** are human-readable documentation generated by GX that host your Expectation Suite definitions and Validation Results. Using Checkpoints and Actions, you can configure your GX workflow to automatically write Validation Results to a chosen Data Docs site.

For more information on defining and running Validations, see [Run Validations](core/run_validations/).


## Guidance for exploratory and production workflows

GX workflows can be built to satisfy a variety of use cases. The two most common types are:
* Exploratory workflows
* Production workflows

This section provides high-level guidance on the differences between exploratory and production GX workflows.

### Interactive and exploratory workflows

GX is a popular choice for validating Pandas and Spark DataFrames. You may employ GX during the exploratory data analysis phase to gain more insight into your data. GX enables you to interactively run Expectations against your in-memory data and immediately view the results.

When using GX in an interactive and exploratory capacity, typically you will:
* [Connect to data in DataFrames](/core/connect_to_data/dataframes/dataframes.md).
* Run your GX workflow code in a notebook or REPL.
* Use an [Ephemeral Data Context](/core/set_up_a_gx_environment/create_a_data_context?context_type=ephemeral), which stores GX environment settings, configuration, and metadata in memory and does not persist outside of the active Python or kernel session.
* Validate Batches directly with Expectations and Expectations Suites.

### Production deployment workflows

GX is a flexible and powerful framework to introduce data validation into a production data pipeline deployment. You may employ GX to implement robust data quality testing and monitoring across your organization's data stores.

When using GX in an production capacity, typically you will:
* [Connect to SQL data](/core/connect_to_data/sql_data/sql_data.md).
* Define your GX workflow as versioned, source-controlled Python code.
* Trigger and run your GX workflow using Python within a pipeline orchestrator (for example, Airflow or Dagster).
* Use a [File Data Context](/core/set_up_a_gx_environment/create_a_data_context?context_type=file), so that GX environment settings, configuration, and metadata can be persisted between validation runs.
* Use Checkpoints, Validation Definitions, and Actions to define how data should be validated as well as how the results should be processed.
* Store your Validation Result history in Data Docs (or [a GX Cloud organization](/cloud/gx_cloud_lp.md)) so that other team members can access the results.

## Next steps

Visit [Try GX](/core/introduction/try_gx.md) to see example workflows implemented using GX Core.