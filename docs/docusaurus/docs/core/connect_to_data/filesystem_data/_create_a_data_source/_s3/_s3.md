import TabItem from '@theme/TabItem';
import Tabs from '@theme/Tabs';

import PrereqPythonInstall from '../../../../_core_components/prerequisites/_python_installation.md'
import PrereqGxInstall from '../../../../_core_components/prerequisites/_gx_installation_with_s3_dependencies.md'
import PrereqDataContext from '../../../../_core_components/prerequisites/_preconfigured_data_context.md'

### Prerequisites
- <PrereqPythonInstall/>
- <PrereqGxInstall/>
  - Optional. To create a Spark Filesystem Data Source you will also need to [install the Spark Python dependencies](/core/set_up_a_gx_environment/install_additional_dependencies.md?dependencies=spark).
- <PrereqDataContext/>
- Access to data files on a S3 bucket.

<Tabs>

<TabItem value="procedure" label="Procedure">

1. Define the Data Source's parameters.

   The following information is required when you create an Amazon S3 Data Source:

   - `name`: A descriptive name used to reference the Data Source.  This should be unique within the Data Context.
   - `bucket_name`: The Amazon S3 bucket name.
   - `boto3_options`: Optional. Additional options for the Data Source. In the following examples, the default values are used.

   Replace the variable values with your own and run the following Python code to define `name`, `bucket_name` and `boto3_options`:

   ```python title="Python"
   data_source_name = "nyc_taxi_data"
   bucket_name = "my_bucket"
   boto3_options = {}
   ```

   :::info Additional options for `boto3_options`

   The parameter `boto3_options` allows you to pass the following information:

   - `region_name`: Your AWS region name.
   - `endpoint_url`: specifies an S3 endpoint.  You can provide an environment variable reference such as `"${S3_ENDPOINT}"` to securely include this in your code.  The string `"${S3_ENDPOINT}"` will be replaced with the value of the environment variable `S3_ENDPOINT`.
   
   For more information on secure storage and retrieval of credentials in GX see [Configure credentials](/core/connect_to_data/sql_data/sql_data.md#configure-credentials).

   :::

2. Add a S3 Filesystem Data Source to your Data Context.

   GX can leverage either pandas or Spark as the backend for your S3 Filesystem Data Source.  To create your Data Source, execute one of the following sets of code:
 
   <Tabs queryString="data_source_type" groupId="data_source_type" defaultValue='pandas_filesystem'>

   <TabItem value="pandas_filesystem" label="pandas">

   ```python title="Python"
   datasource = context.sources.add_pandas_s3(
      name=data_source_name,
      bucket=bucket_name,
      boto3_options=boto3_options
   )
   ```

   </TabItem>

   <TabItem value="spark" label="Spark">

   ```python title="Python"
   datasource = context.sources.add_spark_s3(
      name=data_source_name,
      bucket=bucket_name,
      boto3_options=boto3_options
   )
   ```

   </TabItem>

   </Tabs>

3. Optional. Retrieve your Data Source from your Data Context.

   You can retrieve your Data Source elsewhere in your code by updating the value of `data_source_name` and executing:

   ```python title="Python"
   data_source_name="nyc_taxi_data"
   datasource = context.data_sources.get(data_source_name)
   ```

   If you are using a File Data Context your Data Source can also be retrieved from the Data Context in future python sessions.

</TabItem>

<TabItem value="sample_code" label="Sample code">

   Choose from the following to see the full example code for a S3 Filesystem Data Source, using either pandas or Spark to read the data files:

   <Tabs queryString="data_source_type" groupId="data_source_type" defaultValue='pandas_filesystem'>

   <TabItem value="pandas_filesystem" label="pandas example">

   ```python title="Python"
   import great_epectations as gx

   context = gx.get_context()

   # Define the Data Source's parameters:
   data_source_name = "my_s3_datasource"
   bucket_name = "my_bucket"
   boto3_options = {}
   
   # Create the Data Source:
   datasource = context.sources.add_pandas_s3(
      name=data_source_name,
      bucket=bucket_name,
      boto3_options=boto3_options
   )
   
   # Retrieve the Data Source:
   datasource = context.data_sources.get("nyc_taxi_data")
   ```

   </TabItem>

   <TabItem value="spark" label="Spark example">

   ```python title="Python"
   import great_epectations as gx

   context = gx.get_context()

   # Define the Data Source's parameters:
   data_source_name = "my_s3_datasource"
   bucket_name = "my_bucket"
   boto3_options = {}
   
   # Create the Data Source:
   datasource = context.sources.add_spark_s3(
      name=data_source_name,
      bucket=bucket_name,
      boto3_options=boto3_options
   )

   # Retrieve the Data Source:
   datasource = context.data_sources.get("nyc_taxi_data")
   ```

   </TabItem>

   </Tabs>

</TabItem>

</Tabs>

