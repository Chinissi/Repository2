---
title: Batch
id: batch
hoverText: A selection of records from a Data Asset.
---

import UniversalMap from '/docs/images/universal_map/_universal_map.mdx';
import ValidateHeader from '/docs/images/universal_map/_um_validate_header.mdx';
import CreateHeader from '/docs/images/universal_map/_um_create_header.mdx';

<UniversalMap setup='inactive' connect='inactive' create='active' validate='active'/> 

### What is it?

A Batch is a selection of records from a Data Asset.

### What are its features?

A Batch provides a consistent interface for describing specific data from any Datasource, to support building Metrics, Validation, and Profiling.

### What does it interact with?

A Batch is generated by providing a Batch Request to a Datasource. It provides a reference to interact with the data through the Datasource and adds metadata to precisely identify the specific data included in the Batch.

Profilers use Batches to generate Metrics and potential Expectations based on the data. Batches make it possible for the Profiler to compare data over time and sample from large datasets to improve performance.

Metrics are always associated with a Batch of data. The identifier for the Batch is the primary way that Great Expectations identifies what data to use when computing a Metric and how to store that Metric.

### Use Cases

<CreateHeader/>

When creating Expectations interactively, a Validator needs access to a specific Batch of data against which to check Expectations. The [how to guide on interactively creating expectations](../guides/expectations/how_to_create_and_edit_expectations_with_instant_feedback_from_a_sample_batch_of_data.md) covers using a Batch in this use case.

Our in-depth guide on [how to create and edit expectations with a profiler](../guides/expectations/how_to_create_and_edit_expectations_with_a_profiler.md) covers how to specify which Batches of data should be used when using Great Expectations to generate statistics and candidate Expectations for your data.

<ValidateHeader/>

During Validation, a Checkpoint will check a Batch of data against Expectations from an Expectation Suite. You must specify a Batch Request or provide a Batch of data at runtime for the Checkpoint to run.

### Features

1. Consistent Interface for Describing Specific Data from any Datasource

A Batch is always part of a Data Asset. The Data Asset is sliced into Batches to correspond to the specification you define in a Data Connector, allowing you to define Batches of a Data Asset based on times from the data, pipeline runs, or the time of a Validation.

A Batch is always built using a Batch Request. The Batch Request includes a "query" for the Data Connector to describe the data that will be included in the Batch. The query makes it possible to create a Batch Request for the most recent Batch of data without defining the specific timeframe, for example.

Once a Datasource identifies the specific data that will be included in a Batch based on the Batch Request, it creates a reference to the data, and adds metadata including a Batch Definition, Batch Spec, and Batch Markers. That additional metadata is how Great Expectations identifies the Batch when accessing or storing Metrics.

### APIs

The `BatchRequest` object is the primary API used to construct Batches. It is provided to the `get_validator` method on DataContext.

**JPC -- one note -- this seems like a place where we have th eoption to go into the developer and contributor versions of these APIs differently.**

### Additional Notes

Instantiating a Batch does not necessarily “fetch” the data by immediately running a query or pulling data into memory. Instead, think of a Batch as a wrapper that includes the information that you will need to fetch the right data when it’s time to Validate.

You do not generally need to access the metadata that Great Expectations uses to define a Batch. You can read more about it in the API docs, but at a high level, the additional metadata works as follows:

- *Batch Definition* - A generic description of the Batch built directly from the Batch Request. It is not directly tied to the language of the source system, but it includes the specific parameters for identifying the data that may have been referenced in a relative way in the Batch Request.
- *Batch Spec* - The description of the data in the precise language of the source system or specific Execution Engine associated with the Batch.
- *Batch Markers* - (Advanced) Batch Markers are key-value pairs that can help to even more precisely identify data after Validation, such as the md5 hash of a Pandas DataFrame or the specific timestamp at which a Batch was accessed.


#### Design Motivation

Batches are designed to be "MECE" -- mutually exclusive and collectively exhaustive partitions of Data Assets. However, in many cases the same *underlying data* could be present in multiple batches, for example if an analyst runs an analysis against an entire table of data each day, with only a fraction of new records being added.

Consequently, the best way to understand what "makes a batch a batch" is the act of attending to it. The batch is the fundamental unit that Great Expectations will validate and about which it will collect metrics.