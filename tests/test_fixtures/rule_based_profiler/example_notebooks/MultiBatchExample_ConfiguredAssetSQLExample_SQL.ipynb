{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"7f0a5264-b003-4101-862f-45653f2aed1b\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# How to write multi-batch `BatchRequest` - Configured `Sql` Example\\n\",\n",
    "    \"* A `BatchRequest` facilitates the return of a `batch` of data from a configured `Datasource`. To find more about `Batches`, please refer to the [related documentation](https://docs.greatexpectations.io/docs/guides/connecting_to_your_data/how_to_get_a_batch_of_data_from_a_configured_datasource#1-construct-a-batchrequest). \\n\",\n",
    "    \"* A `BatchRequest` can return 0 or more Batches of data depending on the underlying data, and how it is configured. This guide will help you configure `BatchRequests` to return multiple batches, which can be used by\\n\",\n",
    "    \"   1. Self-Initializing Expectations to estimate parameters\\n\",\n",
    "    \"   2. DataAssistants to profile your data and create and Expectation suite with self-intialized parameters.\\n\",\n",
    "    \"   \\n\",\n",
    "    \"* Note : Multi-batch BatchRequests are not supported in `RuntimeDataConnector`.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 37,\n",
    "   \"id\": \"ee54886b-4f88-46d9-9afe-dfd8bb061e19\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import great_expectations as gx\\n\",\n",
    "    \"from great_expectations.core.yaml_handler import YAMLHandler\\n\",\n",
    "    \"from great_expectations.core.batch import BatchRequest\\n\",\n",
    "    \"import sqlite3\\n\",\n",
    "    \"import pprint\\n\",\n",
    "    \"from ruamel import yaml\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"bfa243d2-6905-403a-b47a-d89ba834b951\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"* Load `DataContext`\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 38,\n",
    "   \"id\": \"45b1854b-2a75-422e-83bb-5509d868e0c5\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"data_context: gx.DataContext = gx.get_context()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"c4462320-d76e-492c-96fb-f0ff8f788851\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Sql Example\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"a6e04726\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Example Database\\n\",\n",
    "    \"\\n\",\n",
    "    \"Imagine we have a database of 1 table, with `yellow_tripdata_sample_2020`, corresponding to all 12 months' `taxi_trip` data for 2020.\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 3,\n",
    "   \"id\": \"cd29b60b-7e16-4978-acee-0dab368cde3c\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"['yellow_tripdata_sample_2019', 'yellow_tripdata_sample_2020']\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# connect to sqlite DB, and print the existing tables\\n\",\n",
    "    \"CONNECTION_STRING = \\\"postgresql+psycopg2://postgres:@localhost/test_ci\\\"\\n\",\n",
    "    \"from sqlalchemy import create_engine\\n\",\n",
    "    \"from sqlalchemy import inspect\\n\",\n",
    "    \"engine = create_engine(CONNECTION_STRING)\\n\",\n",
    "    \"insp = inspect(engine)\\n\",\n",
    "    \"print(insp.get_table_names())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"49515697-83a2-432d-8b74-33e2f01db72c\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Example Configuration\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"df19a29c\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"In our example, we add a `Datasource` named `taxi_multi_batch_sql_datasource` with 1 table. We also have a `ConfiguredAssetSqlDataConnector` named `configured_data_connector_multi_batch_asset`.\\n\",\n",
    "    \"\\n\",\n",
    "    \"The DataConnector contains 2 `assets`, both associated with the `table_name` named`yellow_tripdata_sample_2020`.\\n\",\n",
    "    \"\\n\",\n",
    "    \"The asset `yellow_tripdata_sample_2020_full` contains no other parameter other than the `table_name` and optional `schema_name`, which mean the whole table will be loaded as one Batch in the asset. \\n\",\n",
    "    \"\\n\",\n",
    "    \"The asset `yellow_tripdata_sample_2020_by_year_and_month` contains `table_name` and `schema_name`, as well as a splitter configuration. The splitter we use is `split_on_year_and_month`, which creates Batches according to the `pickup_datetime` column which is of type timestamp in the database schema.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Note**: This example only uses `splitters` but sampling can also be used. For more information, please refer to the document [How to configure a DataConnector for splitting and sampling tables in SQL](https://docs.greatexpectations.io/docs/guides/connecting_to_your_data/advanced/how_to_configure_a_dataconnector_for_splitting_and_sampling_tables_in_sql)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 34,\n",
    "   \"id\": \"84150f65-bbd6-4b45-95ab-9590a29f116a\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Attempting to instantiate class from config...\\n\",\n",
    "      \"\\tInstantiating as a Datasource, since class_name is Datasource\\n\",\n",
    "      \"\\tSuccessfully instantiated Datasource\\n\",\n",
    "      \"\\n\",\n",
    "      \"\\n\",\n",
    "      \"ExecutionEngine class name: SqlAlchemyExecutionEngine\\n\",\n",
    "      \"Data Connectors:\\n\",\n",
    "      \"\\tconfigured_data_connector_multi_batch_asset : ConfiguredAssetSqlDataConnector\\n\",\n",
    "      \"\\n\",\n",
    "      \"\\tAvailable data_asset_names (2 of 2):\\n\",\n",
    "      \"\\t\\tyellow_tripdata_sample_2020_by_year_and_month (3 of 5): [{'pickup_datetime': {'year': 2020, 'month': 5}}, {'pickup_datetime': {'year': 2020, 'month': 4}}, {'pickup_datetime': {'year': 2020, 'month': 3}}]\\n\",\n",
    "      \"\\t\\tyellow_tripdata_sample_2020_full (1 of 1): [{}]\\n\",\n",
    "      \"\\n\",\n",
    "      \"\\tUnmatched data_references (0 of 0):[]\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"<great_expectations.datasource.new_datasource.Datasource at 0x7ff1c46ec160>\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 34,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"datasource_config = {\\n\",\n",
    "    \"    \\\"name\\\": \\\"taxi_multi_batch_sql_datasource\\\",\\n\",\n",
    "    \"    \\\"class_name\\\": \\\"Datasource\\\",\\n\",\n",
    "    \"    \\\"module_name\\\": \\\"great_expectations.datasource\\\",\\n\",\n",
    "    \"    \\\"execution_engine\\\": {\\n\",\n",
    "    \"        \\\"module_name\\\": \\\"great_expectations.execution_engine\\\",\\n\",\n",
    "    \"        \\\"class_name\\\": \\\"SqlAlchemyExecutionEngine\\\",\\n\",\n",
    "    \"        \\\"connection_string\\\": CONNECTION_STRING,\\n\",\n",
    "    \"    },\\n\",\n",
    "    \"    \\\"data_connectors\\\": {\\n\",\n",
    "    \"        \\\"configured_data_connector_multi_batch_asset\\\": {\\n\",\n",
    "    \"            \\\"class_name\\\": \\\"ConfiguredAssetSqlDataConnector\\\",\\n\",\n",
    "    \"            \\\"assets\\\":{\\n\",\n",
    "    \"                \\\"yellow_tripdata_sample_2020_full\\\":\\n\",\n",
    "    \"                {\\n\",\n",
    "    \"                    \\\"table_name\\\": \\\"yellow_tripdata_sample_2020\\\",\\n\",\n",
    "    \"                    \\\"schema_name\\\": \\\"public\\\",\\n\",\n",
    "    \"                },\\n\",\n",
    "    \"    \\n\",\n",
    "    \"                \\\"yellow_tripdata_sample_2020_by_year_and_month\\\":{\\n\",\n",
    "    \"                    \\\"table_name\\\": \\\"yellow_tripdata_sample_2020\\\",\\n\",\n",
    "    \"                    \\\"schema_name\\\": \\\"public\\\",\\n\",\n",
    "    \"                    \\\"splitter_method\\\": \\\"split_on_year_and_month\\\",\\n\",\n",
    "    \"                    \\\"splitter_kwargs\\\": {\\n\",\n",
    "    \"                        \\\"column_name\\\": \\\"pickup_datetime\\\",\\n\",\n",
    "    \"                        },\\n\",\n",
    "    \"                    },\\n\",\n",
    "    \"                },\\n\",\n",
    "    \"            },\\n\",\n",
    "    \"            \\n\",\n",
    "    \"        },\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"data_context.test_yaml_config(yaml.dump(datasource_config))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"635755a4-36b1-442f-968a-2fbdb9b146d8\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"We see we have successfully configured this because the output shows a 2 data assets\\n\",\n",
    "    \"- `yellow_tripdata_sample_2020_full` associated with 1 batch. \\n\",\n",
    "    \"- `yellow_tripdata_sample_2020_by_year_and_month` with 12 batches, each associated with a different month in our `pickup_datetime` column. \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 5,\n",
    "   \"id\": \"7636ffff-0ddc-48fd-a4cf-f8e139a5e36e\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# add_datasource only if it doesn't already exist in our configuration\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    data_context.get_datasource(datasource_config[\\\"name\\\"])\\n\",\n",
    "    \"except ValueError:\\n\",\n",
    "    \"    data_context.add_datasource(**datasource_config)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"438146be\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## BatchRequest\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"117cdb0d\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Depending on how we configured our assets, when you send a `BatchRequest`, you will retrieve a different number of `Batches`\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"87bc9c59\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Single Batch returned by `yellow_tripdata_sample_2020_full`\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 6,\n",
    "   \"id\": \"0453cd3c\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"single_batch_batch_request: BatchRequest = BatchRequest(\\n\",\n",
    "    \"    datasource_name=\\\"taxi_multi_batch_sql_datasource\\\",\\n\",\n",
    "    \"    data_connector_name=\\\"configured_data_connector_multi_batch_asset\\\",\\n\",\n",
    "    \"    data_asset_name=\\\"yellow_tripdata_sample_2020_full\\\",\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 7,\n",
    "   \"id\": \"35df7084\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"batch_list = data_context.get_batch_list(batch_request=single_batch_batch_request)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 8,\n",
    "   \"id\": \"d8e74a05-3fd1-4e47-9105-b721dbcf3516\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"[<great_expectations.core.batch.Batch at 0x7ff1c43336a0>]\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 8,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"batch_list\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"be7f4fa5\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Multi Batch returned by `yellow_tripdata_sample_2020_by_year_and_month`\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 31,\n",
    "   \"id\": \"c32dbac9-af5d-4677-98f9-f098ef091b6f\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"multi_batch_batch_request: BatchRequest = BatchRequest(\\n\",\n",
    "    \"    datasource_name=\\\"taxi_multi_batch_sql_datasource\\\",\\n\",\n",
    "    \"    data_connector_name=\\\"configured_data_connector_multi_batch_asset\\\",\\n\",\n",
    "    \"    data_asset_name=\\\"yellow_tripdata_sample_2020_by_year_and_month\\\",\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 32,\n",
    "   \"id\": \"3a284bfd-00aa-4068-bc09-71c6dea627e0\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"multi_batch_batch_list = data_context.get_batch_list(batch_request=multi_batch_batch_request)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 33,\n",
    "   \"id\": \"7bf3e1ff\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"[<great_expectations.core.batch.Batch at 0x7ff1c46f4730>,\\n\",\n",
    "       \" <great_expectations.core.batch.Batch at 0x7ff1c429b940>,\\n\",\n",
    "       \" <great_expectations.core.batch.Batch at 0x7ff1c45794f0>,\\n\",\n",
    "       \" <great_expectations.core.batch.Batch at 0x7ff1c469bac0>,\\n\",\n",
    "       \" <great_expectations.core.batch.Batch at 0x7ff1c42aa370>]\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 33,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"multi_batch_batch_list # 12 batches\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"790746ee\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"You can also get a single Batch from a multi-batch DataConnector by passing in `data_connector_query`. \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 12,\n",
    "   \"id\": \"16612bb4\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"single_batch_batch_request_from_multi: BatchRequest = BatchRequest(\\n\",\n",
    "    \"    datasource_name=\\\"taxi_multi_batch_sql_datasource\\\",\\n\",\n",
    "    \"    data_connector_name=\\\"configured_data_connector_multi_batch_asset\\\",\\n\",\n",
    "    \"    data_asset_name=\\\"yellow_tripdata_sample_2020_by_year_and_month\\\",\\n\",\n",
    "    \"    data_connector_query={ \\n\",\n",
    "    \"        \\\"batch_filter_parameters\\\": {\\\"pickup_datetime\\\": {\\\"year\\\": 2020, \\\"month\\\": 1}}\\n\",\n",
    "    \"    }\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 13,\n",
    "   \"id\": \"6ef1b6a9\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"batch_list = data_context.get_batch_list(batch_request=single_batch_batch_request_from_multi)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 14,\n",
    "   \"id\": \"80a69e96\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"[<great_expectations.core.batch.Batch at 0x7ff1dbe703d0>]\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 14,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"batch_list # has a length of 1, as expected\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"26cd5a37\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Let's review our batch:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 15,\n",
    "   \"id\": \"229815cd\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"batch = batch_list[0]  # our single filtered batch with 'batch_identifiers': {'pickup_datetime': '2020-01'}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 16,\n",
    "   \"id\": \"f2be5bdb\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"{'data': '<great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7ff1c42fb340>',\\n\",\n",
    "       \" 'batch_request': {'datasource_name': 'taxi_multi_batch_sql_datasource',\\n\",\n",
    "       \"  'data_connector_name': 'configured_data_connector_multi_batch_asset',\\n\",\n",
    "       \"  'data_asset_name': 'yellow_tripdata_sample_2020_by_year_and_month',\\n\",\n",
    "       \"  'limit': None,\\n\",\n",
    "       \"  'batch_spec_passthrough': None,\\n\",\n",
    "       \"  'data_connector_query': {'batch_filter_parameters': {'pickup_datetime': {'year': 2020,\\n\",\n",
    "       \"     'month': 1}}}},\\n\",\n",
    "       \" 'batch_definition': {'datasource_name': 'taxi_multi_batch_sql_datasource',\\n\",\n",
    "       \"  'data_connector_name': 'configured_data_connector_multi_batch_asset',\\n\",\n",
    "       \"  'data_asset_name': 'yellow_tripdata_sample_2020_by_year_and_month',\\n\",\n",
    "       \"  'batch_identifiers': {'pickup_datetime': {'year': 2020, 'month': 1}}},\\n\",\n",
    "       \" 'batch_spec': {'data_asset_name': 'yellow_tripdata_sample_2020_by_year_and_month',\\n\",\n",
    "       \"  'table_name': 'yellow_tripdata_sample_2020',\\n\",\n",
    "       \"  'batch_identifiers': {'pickup_datetime': {'year': 2020, 'month': 1}},\\n\",\n",
    "       \"  'class_name': 'Asset',\\n\",\n",
    "       \"  'schema_name': 'public',\\n\",\n",
    "       \"  'splitter_method': 'split_on_year_and_month',\\n\",\n",
    "       \"  'module_name': 'great_expectations.datasource.data_connector.asset',\\n\",\n",
    "       \"  'splitter_kwargs': {'column_name': 'pickup_datetime'},\\n\",\n",
    "       \"  'type': None},\\n\",\n",
    "       \" 'batch_markers': {'ge_load_time': '20220913T024332.529136Z'}}\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 16,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"batch.to_dict()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"907a6ef5\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Using auto-initializing `Expectations` to generate parameters\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"6efe9c76\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"We will generate a `Validator` using our `multi_batch_batch_list`\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 17,\n",
    "   \"id\": \"847ce4a3\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"multi_batch_batch_list = data_context.get_batch_list(batch_request=multi_batch_batch_request)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 18,\n",
    "   \"id\": \"a1eca55b\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"example_suite = data_context.create_expectation_suite(expectation_suite_name=\\\"example_sql_suite\\\", overwrite_existing=True)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 19,\n",
    "   \"id\": \"852deba1\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"validator = data_context.get_validator_using_batch_list(batch_list=multi_batch_batch_list, expectation_suite=example_suite)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"ee01a0e9\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"When you run methods on the validator, it will typically run on the most recent batch (index `-1`), even if the Validator has access to a longer Batch list. For example, notice that rows below are all associated with `pickup_datetime` being `9` (September, 2020). This is because the datetime values are stored lexicographically, meaning `1` and `11`, `12` values will appear **before** `2` and `3`.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"d8d7d827-ed51-4f83-ac41-33ae58416ef1\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"For simplicity, let's get a `validator` with the December `Batch`, which is in index `\\\"3\\\"` (after `1`, `10`, `11`). Notice that we are also casting the value as a `list` using the square brackets. \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 20,\n",
    "   \"id\": \"11b673bc-8583-4fc5-9aa0-db6ca62e240c\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"validator = data_context.get_validator_using_batch_list(batch_list=[multi_batch_batch_list[3]], expectation_suite=example_suite)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 21,\n",
    "   \"id\": \"ffe9cabd-b2bd-46de-9317-ba4e809342fa\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"model_id\": \"7f1f7a3134bc4325b15d750c12b018bf\",\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0\n",
    "      },\n",
    "      \"text/plain\": [\n",
    "       \"Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>vendor_id</th>\\n\",\n",
    "       \"      <th>pickup_datetime</th>\\n\",\n",
    "       \"      <th>dropoff_datetime</th>\\n\",\n",
    "       \"      <th>passenger_count</th>\\n\",\n",
    "       \"      <th>trip_distance</th>\\n\",\n",
    "       \"      <th>rate_code_id</th>\\n\",\n",
    "       \"      <th>store_and_fwd_flag</th>\\n\",\n",
    "       \"      <th>pickup_location_id</th>\\n\",\n",
    "       \"      <th>dropoff_location_id</th>\\n\",\n",
    "       \"      <th>payment_type</th>\\n\",\n",
    "       \"      <th>fare_amount</th>\\n\",\n",
    "       \"      <th>extra</th>\\n\",\n",
    "       \"      <th>mta_tax</th>\\n\",\n",
    "       \"      <th>tip_amount</th>\\n\",\n",
    "       \"      <th>tolls_amount</th>\\n\",\n",
    "       \"      <th>improvement_surcharge</th>\\n\",\n",
    "       \"      <th>total_amount</th>\\n\",\n",
    "       \"      <th>congestion_surcharge</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>2.0</td>\\n\",\n",
    "       \"      <td>2020-04-03 16:23:46</td>\\n\",\n",
    "       \"      <td>2020-04-03 16:34:42</td>\\n\",\n",
    "       \"      <td>5.0</td>\\n\",\n",
    "       \"      <td>2.26</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>N</td>\\n\",\n",
    "       \"      <td>263</td>\\n\",\n",
    "       \"      <td>41</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>10.0</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>0.5</td>\\n\",\n",
    "       \"      <td>2.86</td>\\n\",\n",
    "       \"      <td>0.0</td>\\n\",\n",
    "       \"      <td>0.3</td>\\n\",\n",
    "       \"      <td>17.16</td>\\n\",\n",
    "       \"      <td>2.5</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>2020-04-29 09:45:35</td>\\n\",\n",
    "       \"      <td>2020-04-29 09:48:36</td>\\n\",\n",
    "       \"      <td>0.0</td>\\n\",\n",
    "       \"      <td>0.40</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>N</td>\\n\",\n",
    "       \"      <td>43</td>\\n\",\n",
    "       \"      <td>151</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>4.0</td>\\n\",\n",
    "       \"      <td>0.0</td>\\n\",\n",
    "       \"      <td>0.5</td>\\n\",\n",
    "       \"      <td>0.00</td>\\n\",\n",
    "       \"      <td>0.0</td>\\n\",\n",
    "       \"      <td>0.3</td>\\n\",\n",
    "       \"      <td>4.80</td>\\n\",\n",
    "       \"      <td>0.0</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>2020-04-27 19:21:48</td>\\n\",\n",
    "       \"      <td>2020-04-27 19:29:07</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>2.80</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>N</td>\\n\",\n",
    "       \"      <td>140</td>\\n\",\n",
    "       \"      <td>107</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>10.0</td>\\n\",\n",
    "       \"      <td>3.5</td>\\n\",\n",
    "       \"      <td>0.5</td>\\n\",\n",
    "       \"      <td>3.55</td>\\n\",\n",
    "       \"      <td>0.0</td>\\n\",\n",
    "       \"      <td>0.3</td>\\n\",\n",
    "       \"      <td>17.85</td>\\n\",\n",
    "       \"      <td>2.5</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>2.0</td>\\n\",\n",
    "       \"      <td>2020-04-23 18:01:29</td>\\n\",\n",
    "       \"      <td>2020-04-23 18:06:14</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>1.03</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>N</td>\\n\",\n",
    "       \"      <td>142</td>\\n\",\n",
    "       \"      <td>238</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>6.0</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>0.5</td>\\n\",\n",
    "       \"      <td>2.58</td>\\n\",\n",
    "       \"      <td>0.0</td>\\n\",\n",
    "       \"      <td>0.3</td>\\n\",\n",
    "       \"      <td>12.88</td>\\n\",\n",
    "       \"      <td>2.5</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>2020-04-29 09:02:24</td>\\n\",\n",
    "       \"      <td>2020-04-29 09:08:48</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>0.80</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>N</td>\\n\",\n",
    "       \"      <td>161</td>\\n\",\n",
    "       \"      <td>100</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>6.0</td>\\n\",\n",
    "       \"      <td>2.5</td>\\n\",\n",
    "       \"      <td>0.5</td>\\n\",\n",
    "       \"      <td>2.30</td>\\n\",\n",
    "       \"      <td>0.0</td>\\n\",\n",
    "       \"      <td>0.3</td>\\n\",\n",
    "       \"      <td>11.60</td>\\n\",\n",
    "       \"      <td>2.5</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ],\n",
    "      \"text/plain\": [\n",
    "       \"   vendor_id     pickup_datetime    dropoff_datetime  passenger_count  \\\\\\n\",\n",
    "       \"0        2.0 2020-04-03 16:23:46 2020-04-03 16:34:42              5.0   \\n\",\n",
    "       \"1        1.0 2020-04-29 09:45:35 2020-04-29 09:48:36              0.0   \\n\",\n",
    "       \"2        1.0 2020-04-27 19:21:48 2020-04-27 19:29:07              1.0   \\n\",\n",
    "       \"3        2.0 2020-04-23 18:01:29 2020-04-23 18:06:14              1.0   \\n\",\n",
    "       \"4        1.0 2020-04-29 09:02:24 2020-04-29 09:08:48              1.0   \\n\",\n",
    "       \"\\n\",\n",
    "       \"   trip_distance  rate_code_id store_and_fwd_flag  pickup_location_id  \\\\\\n\",\n",
    "       \"0           2.26           1.0                  N                 263   \\n\",\n",
    "       \"1           0.40           1.0                  N                  43   \\n\",\n",
    "       \"2           2.80           1.0                  N                 140   \\n\",\n",
    "       \"3           1.03           1.0                  N                 142   \\n\",\n",
    "       \"4           0.80           1.0                  N                 161   \\n\",\n",
    "       \"\\n\",\n",
    "       \"   dropoff_location_id  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\\\\n\",\n",
    "       \"0                   41           1.0         10.0    1.0      0.5        2.86   \\n\",\n",
    "       \"1                  151           1.0          4.0    0.0      0.5        0.00   \\n\",\n",
    "       \"2                  107           1.0         10.0    3.5      0.5        3.55   \\n\",\n",
    "       \"3                  238           1.0          6.0    1.0      0.5        2.58   \\n\",\n",
    "       \"4                  100           1.0          6.0    2.5      0.5        2.30   \\n\",\n",
    "       \"\\n\",\n",
    "       \"   tolls_amount  improvement_surcharge  total_amount  congestion_surcharge  \\n\",\n",
    "       \"0           0.0                    0.3         17.16                   2.5  \\n\",\n",
    "       \"1           0.0                    0.3          4.80                   0.0  \\n\",\n",
    "       \"2           0.0                    0.3         17.85                   2.5  \\n\",\n",
    "       \"3           0.0                    0.3         12.88                   2.5  \\n\",\n",
    "       \"4           0.0                    0.3         11.60                   2.5  \"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 21,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"validator.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"8be66602\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Typical Workflow\\n\",\n",
    "    \"A `batch_list` becomes really useful when you are calculating parameters for auto-initializing Expectations, as they use a `RuleBasedProfiler` under-the-hood to calculate parameters.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"fdef9ad7\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Let's say we don't know the `min_value` and `max_value` for `expect_column_median_to_be_between()` so we \\\"guess\\\" at the `min_value` and `max_value`.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 22,\n",
    "   \"id\": \"d7642647\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"validator = data_context.get_validator_using_batch_list(batch_list=multi_batch_batch_list, expectation_suite=example_suite)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 23,\n",
    "   \"id\": \"b524a2df\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"model_id\": \"bdc46d7f52834ae9a8dcea9d19d51689\",\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0\n",
    "      },\n",
    "      \"text/plain\": [\n",
    "       \"Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"{\\n\",\n",
    "       \"  \\\"success\\\": false,\\n\",\n",
    "       \"  \\\"result\\\": {\\n\",\n",
    "       \"    \\\"observed_value\\\": 1.99\\n\",\n",
    "       \"  },\\n\",\n",
    "       \"  \\\"meta\\\": {},\\n\",\n",
    "       \"  \\\"exception_info\\\": {\\n\",\n",
    "       \"    \\\"raised_exception\\\": false,\\n\",\n",
    "       \"    \\\"exception_traceback\\\": null,\\n\",\n",
    "       \"    \\\"exception_message\\\": null\\n\",\n",
    "       \"  }\\n\",\n",
    "       \"}\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 23,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"validator.expect_column_median_to_be_between(column=\\\"trip_distance\\\", min_value=0, max_value=1)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"f18d096f\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"The observed value of `trip_distance` for our `yellow_tripdata_sample_2020` going to be `1.75`, which means the Expectation fails. We guessed wrong - but we can do better!\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"9c5016d8\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Now we run the same expectation again, but this time with `auto=True`. This means the median values are going to calculated across the `batch_list` associated with the `Validator` (ie 12 Batches for `yellow_tripdata_sample_2020`), which gives the min value of `1.6` and the max value of `1.99`.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 24,\n",
    "   \"id\": \"cdd821c3\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"model_id\": \"7aa4929f2b514494af1dc0ffdf7a9f5f\",\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0\n",
    "      },\n",
    "      \"text/plain\": [\n",
    "       \"Generating Expectations:   0%|          | 0/1 [00:00<?, ?it/s]\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"model_id\": \"\",\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0\n",
    "      },\n",
    "      \"text/plain\": [\n",
    "       \"Profiling Dataset:         0%|          | 0/1 [00:00<?, ?it/s]\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"model_id\": \"44d2b5cb838845a4a677bb74ad7b45e5\",\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0\n",
    "      },\n",
    "      \"text/plain\": [\n",
    "       \"Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"{\\n\",\n",
    "       \"  \\\"success\\\": true,\\n\",\n",
    "       \"  \\\"expectation_config\\\": {\\n\",\n",
    "       \"    \\\"expectation_type\\\": \\\"expect_column_median_to_be_between\\\",\\n\",\n",
    "       \"    \\\"kwargs\\\": {\\n\",\n",
    "       \"      \\\"column\\\": \\\"trip_distance\\\",\\n\",\n",
    "       \"      \\\"min_value\\\": 1.6,\\n\",\n",
    "       \"      \\\"max_value\\\": 1.99,\\n\",\n",
    "       \"      \\\"strict_min\\\": false,\\n\",\n",
    "       \"      \\\"strict_max\\\": false\\n\",\n",
    "       \"    },\\n\",\n",
    "       \"    \\\"meta\\\": {\\n\",\n",
    "       \"      \\\"auto_generated_at\\\": \\\"20220913T024338.419229Z\\\",\\n\",\n",
    "       \"      \\\"great_expectations_version\\\": \\\"0.15.22+29.g8fc1586df\\\"\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"  },\\n\",\n",
    "       \"  \\\"result\\\": {\\n\",\n",
    "       \"    \\\"observed_value\\\": 1.99\\n\",\n",
    "       \"  },\\n\",\n",
    "       \"  \\\"meta\\\": {},\\n\",\n",
    "       \"  \\\"exception_info\\\": {\\n\",\n",
    "       \"    \\\"raised_exception\\\": false,\\n\",\n",
    "       \"    \\\"exception_traceback\\\": null,\\n\",\n",
    "       \"    \\\"exception_message\\\": null\\n\",\n",
    "       \"  }\\n\",\n",
    "       \"}\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 24,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"validator.expect_column_median_to_be_between(column=\\\"trip_distance\\\", auto=True)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"c6a6c277\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"The auto=True will also automatically run the Expectation against the most recent Batch (which has an observed value of `1.75`) and the Expectation will pass.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"90b8b938\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"You can now save the `ExpectationSuite`.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 25,\n",
    "   \"id\": \"eba880ed\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"validator.save_expectation_suite()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"1b7ec631\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Running the `ExpectationSuite` against single `Batch`\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"477381f5\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Now the ExpectationSuite we built using all batches can be used to validate single batches using a Checkpoint. For example, we can run this checkpoint on new data when it comes in next month. In our example, let's validatidate a different batch from February 2020, using the ExpectationSuite we built from `yellow_tripdata_sample_2020`.\\n\",\n",
    "    \"\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 26,\n",
    "   \"id\": \"747dea95\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"single_batch_batch_request_from_multi: BatchRequest = BatchRequest(\\n\",\n",
    "    \"    datasource_name=\\\"taxi_multi_batch_sql_datasource\\\",\\n\",\n",
    "    \"    data_connector_name=\\\"configured_data_connector_multi_batch_asset\\\",\\n\",\n",
    "    \"    data_asset_name=\\\"yellow_tripdata_sample_2020_by_year_and_month\\\",\\n\",\n",
    "    \"    data_connector_query={ \\n\",\n",
    "    \"        \\\"batch_filter_parameters\\\": {\\\"pickup_datetime\\\": {\\\"year\\\": 2020, \\\"month\\\": 2}}\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \")\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 27,\n",
    "   \"id\": \"cb93d87f\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"{\\n\",\n",
    "       \"  \\\"action_list\\\": [\\n\",\n",
    "       \"    {\\n\",\n",
    "       \"      \\\"name\\\": \\\"store_validation_result\\\",\\n\",\n",
    "       \"      \\\"action\\\": {\\n\",\n",
    "       \"        \\\"class_name\\\": \\\"StoreValidationResultAction\\\"\\n\",\n",
    "       \"      }\\n\",\n",
    "       \"    },\\n\",\n",
    "       \"    {\\n\",\n",
    "       \"      \\\"name\\\": \\\"store_evaluation_params\\\",\\n\",\n",
    "       \"      \\\"action\\\": {\\n\",\n",
    "       \"        \\\"class_name\\\": \\\"StoreEvaluationParametersAction\\\"\\n\",\n",
    "       \"      }\\n\",\n",
    "       \"    },\\n\",\n",
    "       \"    {\\n\",\n",
    "       \"      \\\"name\\\": \\\"update_data_docs\\\",\\n\",\n",
    "       \"      \\\"action\\\": {\\n\",\n",
    "       \"        \\\"class_name\\\": \\\"UpdateDataDocsAction\\\",\\n\",\n",
    "       \"        \\\"site_names\\\": []\\n\",\n",
    "       \"      }\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"  ],\\n\",\n",
    "       \"  \\\"batch_request\\\": {},\\n\",\n",
    "       \"  \\\"class_name\\\": \\\"Checkpoint\\\",\\n\",\n",
    "       \"  \\\"config_version\\\": 1.0,\\n\",\n",
    "       \"  \\\"evaluation_parameters\\\": {},\\n\",\n",
    "       \"  \\\"module_name\\\": \\\"great_expectations.checkpoint\\\",\\n\",\n",
    "       \"  \\\"name\\\": \\\"my_checkpoint\\\",\\n\",\n",
    "       \"  \\\"profilers\\\": [],\\n\",\n",
    "       \"  \\\"runtime_configuration\\\": {},\\n\",\n",
    "       \"  \\\"validations\\\": [\\n\",\n",
    "       \"    {\\n\",\n",
    "       \"      \\\"batch_request\\\": {\\n\",\n",
    "       \"        \\\"datasource_name\\\": \\\"taxi_multi_batch_sql_datasource\\\",\\n\",\n",
    "       \"        \\\"data_connector_name\\\": \\\"configured_data_connector_multi_batch_asset\\\",\\n\",\n",
    "       \"        \\\"data_asset_name\\\": \\\"yellow_tripdata_sample_2020_by_year_and_month\\\",\\n\",\n",
    "       \"        \\\"data_connector_query\\\": {\\n\",\n",
    "       \"          \\\"batch_filter_parameters\\\": {\\n\",\n",
    "       \"            \\\"pickup_datetime\\\": {\\n\",\n",
    "       \"              \\\"year\\\": 2020,\\n\",\n",
    "       \"              \\\"month\\\": 2\\n\",\n",
    "       \"            }\\n\",\n",
    "       \"          }\\n\",\n",
    "       \"        }\\n\",\n",
    "       \"      },\\n\",\n",
    "       \"      \\\"expectation_suite_name\\\": \\\"example_sql_suite\\\"\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"  ]\\n\",\n",
    "       \"}\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 27,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"checkpoint_config = {\\n\",\n",
    "    \"    \\\"name\\\": \\\"my_checkpoint\\\",\\n\",\n",
    "    \"    \\\"config_version\\\": 1,\\n\",\n",
    "    \"    \\\"class_name\\\": \\\"SimpleCheckpoint\\\",\\n\",\n",
    "    \"    \\\"validations\\\": [\\n\",\n",
    "    \"        {\\n\",\n",
    "    \"            \\\"batch_request\\\": single_batch_batch_request_from_multi,\\n\",\n",
    "    \"            \\\"expectation_suite_name\\\": \\\"example_sql_suite\\\",            \\n\",\n",
    "    \"        }\\n\",\n",
    "    \"    ],\\n\",\n",
    "    \"}\\n\",\n",
    "    \"data_context.add_checkpoint(**checkpoint_config)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 28,\n",
    "   \"id\": \"3269dfba\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"model_id\": \"dda39f32a2424457bb73f1197bd904f3\",\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0\n",
    "      },\n",
    "      \"text/plain\": [\n",
    "       \"Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"results = data_context.run_checkpoint(\\n\",\n",
    "    \"    checkpoint_name=\\\"my_checkpoint\\\"\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 29,\n",
    "   \"id\": \"c6234082\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"True\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 29,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"results.success\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"6737ccdd\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Appendix\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"6914725d-85cc-4c9d-a93d-2d1c329eac74\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Other Parameters for `ConfiguredAssetSqlDataConnector`\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"f8e62691\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"The signature of the `ConfiguredAssetSqlDataConnector` also contains the following parameters: \\n\",\n",
    "    \"\\n\",\n",
    "    \"The following required parameters:\\n\",\n",
    "    \"* `name`: The name of this DataConnector.\\n\",\n",
    "    \"* `datasource_name`: The name of the Datasource that contains it.\\n\",\n",
    "    \"* `execution_engine`: the type of ExecutionEngine to use.\\n\",\n",
    "    \"* `assets`: The dictionary containing the asset configurations.\\n\",\n",
    "    \"\\n\",\n",
    "    \"The `assets` dictionary can contain the following keys and values:\\n\",\n",
    "    \"* `table_name`: string that defines the `table_name` associated with the asset. If table_name is omitted, then the `table_name` defaults to the asset name.\\n\",\n",
    "    \"* `schema_name`: optional string that defines the `schema` for the asset.\\n\",\n",
    "    \"* `include_schema_name`: A `bool` that determines, \\\"Should the `data_asset_name` include the `schema` as a prefix?\\\"\\n\",\n",
    "    \"* `splitter_method`: string that names method to split the target table into multiple `Batches`.\\n\",\n",
    "    \"* `splitter_kwargs`: a dict containing arguments to pass to `splitter_method`.\\n\",\n",
    "    \"* `sampling_method`: string that names method to downsample within a target `Batch`.\\n\",\n",
    "    \"* `sampling_kwargs` : dictionary with keyword arguments to pass to `sampling_method`.\\n\",\n",
    "    \"* `batch_spec_passthrough`: dictionary with keys that will be added directly to `batch_spec`.\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"For more information on `splitters` and `samplers` please consider the following documentation: [How to configure a DataConnector for splitting and sampling tables in SQL](https://docs.greatexpectations.io/docs/guides/connecting_to_your_data/advanced/how_to_configure_a_dataconnector_for_splitting_and_sampling_tables_in_sql)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"10a27510\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Configuring Splitters at `DataConnector` and `Asset`-Level\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"7fb9c585\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"For `ConfiguredAssetSqlDataConnectors`, the `splitter_method` and `splitter_kwargs` can be configured at the `DataConnector`-level or `Asset`-level. \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"263ed79f\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"#### Configuration at `DataConnector`-level\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"baad2c0d\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"\\n\",\n",
    "    \"Here is a configuration with the splitter method `split_on_year_and_month` configured at the `DataConnector`-level for a `DataConnector` with 2 `Assets`, `yellow_tripdata_sample_2020_by_year_and_month` and `yellow_tripdata_sample_2020`\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 30,\n",
    "   \"id\": \"85b9598e\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Attempting to instantiate class from config...\\n\",\n",
    "      \"\\tInstantiating as a Datasource, since class_name is Datasource\\n\",\n",
    "      \"\\tSuccessfully instantiated Datasource\\n\",\n",
    "      \"\\n\",\n",
    "      \"\\n\",\n",
    "      \"ExecutionEngine class name: SqlAlchemyExecutionEngine\\n\",\n",
    "      \"Data Connectors:\\n\",\n",
    "      \"\\tconfigured_data_connector_multi_batch_asset : ConfiguredAssetSqlDataConnector\\n\",\n",
    "      \"\\n\",\n",
    "      \"\\tAvailable data_asset_names (2 of 2):\\n\",\n",
    "      \"\\t\\tyellow_tripdata_sample_2020 (3 of 5): [{'pickup_datetime': {'year': 2020, 'month': 5}}, {'pickup_datetime': {'year': 2020, 'month': 4}}, {'pickup_datetime': {'year': 2020, 'month': 3}}]\\n\",\n",
    "      \"\\t\\tyellow_tripdata_sample_2020_by_year_and_month (3 of 5): [{'pickup_datetime': {'year': 2020, 'month': 5}}, {'pickup_datetime': {'year': 2020, 'month': 4}}, {'pickup_datetime': {'year': 2020, 'month': 3}}]\\n\",\n",
    "      \"\\n\",\n",
    "      \"\\tUnmatched data_references (0 of 0):[]\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"<great_expectations.datasource.new_datasource.Datasource at 0x7ff1c4564070>\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 30,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"datasource_config = {\\n\",\n",
    "    \"    \\\"name\\\": \\\"taxi_multi_batch_sql_datasource\\\",\\n\",\n",
    "    \"    \\\"class_name\\\": \\\"Datasource\\\",\\n\",\n",
    "    \"    \\\"module_name\\\": \\\"great_expectations.datasource\\\",\\n\",\n",
    "    \"    \\\"execution_engine\\\": {\\n\",\n",
    "    \"        \\\"module_name\\\": \\\"great_expectations.execution_engine\\\",\\n\",\n",
    "    \"        \\\"class_name\\\": \\\"SqlAlchemyExecutionEngine\\\",\\n\",\n",
    "    \"        \\\"connection_string\\\": CONNECTION_STRING,\\n\",\n",
    "    \"    },\\n\",\n",
    "    \"    \\\"data_connectors\\\": {\\n\",\n",
    "    \"        \\\"configured_data_connector_multi_batch_asset\\\": {\\n\",\n",
    "    \"            \\\"class_name\\\": \\\"ConfiguredAssetSqlDataConnector\\\",\\n\",\n",
    "    \"            \\\"splitter_method\\\": \\\"split_on_year_and_month\\\",\\n\",\n",
    "    \"            \\\"splitter_kwargs\\\": {\\n\",\n",
    "    \"                \\\"column_name\\\": \\\"pickup_datetime\\\",\\n\",\n",
    "    \"            },\\n\",\n",
    "    \"            \\\"assets\\\":{\\n\",\n",
    "    \"    \\n\",\n",
    "    \"                \\\"yellow_tripdata_sample_2020_by_year_and_month\\\":{\\n\",\n",
    "    \"                    \\\"table_name\\\": \\\"yellow_tripdata_sample_2020\\\",\\n\",\n",
    "    \"                    \\\"schema_name\\\": \\\"public\\\",\\n\",\n",
    "    \"                },\\n\",\n",
    "    \"                \\\"yellow_tripdata_sample_2020\\\":{\\n\",\n",
    "    \"                    \\\"table_name\\\": \\\"yellow_tripdata_sample_2020\\\",\\n\",\n",
    "    \"                    \\\"schema_name\\\": \\\"public\\\",\\n\",\n",
    "    \"                },\\n\",\n",
    "    \"            },\\n\",\n",
    "    \"            \\n\",\n",
    "    \"        },\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"data_context.test_yaml_config(yaml.dump(datasource_config))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"2f36497e\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"As you can see, both `Assets`, `yellow_tripdata_sample_2020_by_year_and_month` **and** `yellow_tripdata_sample_2020` have the splitter method applied to it, meaning they both have 12 Batches as a result of splitting by `year` and `month`.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"162c74bc\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"#### Configuration at `DataConnector`-level **and** `Asset`-level\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"7d2134d3\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Next we have a similar example, but with a second `splitter_method` also configured at the `Asset`-level. This time we will configure a second `splitter_method`, `split_on_year_and_month_and_day`, for the Asset `yellow_tripdata_sample_2020_by_year_and_month_and_day`. In this case, the `Asset`-level configuration will **override** the configuration at the `DataConnector`-level and produce 366 Batches as a result of splitting by `year`, `month` and `day`.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"bd803494\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"datasource_config = {\\n\",\n",
    "    \"    \\\"name\\\": \\\"taxi_multi_batch_sql_datasource\\\",\\n\",\n",
    "    \"    \\\"class_name\\\": \\\"Datasource\\\",\\n\",\n",
    "    \"    \\\"module_name\\\": \\\"great_expectations.datasource\\\",\\n\",\n",
    "    \"    \\\"execution_engine\\\": {\\n\",\n",
    "    \"        \\\"module_name\\\": \\\"great_expectations.execution_engine\\\",\\n\",\n",
    "    \"        \\\"class_name\\\": \\\"SqlAlchemyExecutionEngine\\\",\\n\",\n",
    "    \"        \\\"connection_string\\\": CONNECTION_STRING,\\n\",\n",
    "    \"    },\\n\",\n",
    "    \"    \\\"data_connectors\\\": {\\n\",\n",
    "    \"        \\\"configured_data_connector_multi_batch_asset\\\": {\\n\",\n",
    "    \"            \\\"class_name\\\": \\\"ConfiguredAssetSqlDataConnector\\\",\\n\",\n",
    "    \"            \\\"splitter_method\\\": \\\"split_on_year_and_month\\\",\\n\",\n",
    "    \"            \\\"splitter_kwargs\\\": {\\n\",\n",
    "    \"                \\\"column_name\\\": \\\"pickup_datetime\\\",\\n\",\n",
    "    \"            },\\n\",\n",
    "    \"            \\\"assets\\\":{\\n\",\n",
    "    \"    \\n\",\n",
    "    \"                \\\"yellow_tripdata_sample_2020_by_year_and_month\\\":{\\n\",\n",
    "    \"                    \\\"table_name\\\": \\\"yellow_tripdata_sample_2020\\\",\\n\",\n",
    "    \"                    \\\"schema_name\\\": \\\"public\\\",\\n\",\n",
    "    \"                },\\n\",\n",
    "    \"                \\\"yellow_tripdata_sample_2020_by_year_and_month_and_day\\\":{\\n\",\n",
    "    \"                    \\\"table_name\\\": \\\"yellow_tripdata_sample_2020\\\",\\n\",\n",
    "    \"                    \\\"schema_name\\\": \\\"public\\\",\\n\",\n",
    "    \"                    \\\"splitter_method\\\": \\\"split_on_year_and_month_and_day\\\",\\n\",\n",
    "    \"                    \\\"splitter_kwargs\\\": {\\n\",\n",
    "    \"                        \\\"column_name\\\": \\\"pickup_datetime\\\",\\n\",\n",
    "    \"                    },\\n\",\n",
    "    \"                },\\n\",\n",
    "    \"            },\\n\",\n",
    "    \"            \\n\",\n",
    "    \"        },\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"data_context.test_yaml_config(yaml.dump(datasource_config))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"80ff49fe\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"As you can see, `yellow_tripdata_sample_2020_by_year_and_month` and `yellow_tripdata_sample_2020_by_year_and_month_and_day` each have a different number of Batches resulting from their different `splitter` configurations. \\n\",\n",
    "    \"\\n\",\n",
    "    \"* `yellow_tripdata_sample_2020_by_year_and_month` has 12 Batches. \\n\",\n",
    "    \"* `yellow_tripdata_sample_2020_by_year_and_month_and_day` has 366 Batches.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"83ecebdc\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Loading Data into Postgresql Database\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"9f4a183e-f0df-40f4-b64f-439666e32ab4\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"* The following code can be used to build the postgres database used in this notebook. It is included (and commented out) for reference.\\n\",\n",
    "    \"* In order to load the data into a local `postgresql` database, please feel free to use the `docker-compose.yml` file available at `great_expectations/assets/docker/postgresql/`. \\n\",\n",
    "    \"\\n\",\n",
    "    \"### To spin up the `postgresql` database\\n\",\n",
    "    \"* Have [Docker Desktop](https://www.docker.com/products/docker-desktop/) running locally.\\n\",\n",
    "    \"* Navigate to `great_expectations/assets/docker/postgresql/`\\n\",\n",
    "    \"* Type `docker-compose up`\\n\",\n",
    "    \"* Then uncomment and run the following snippet\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 36,\n",
    "   \"id\": \"ad91c234-06a2-4e98-9d90-c999c2aad07f\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-01.csv']\\n\",\n",
    "      \"Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-02.csv']\\n\",\n",
    "      \"Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-03.csv']\\n\",\n",
    "      \"Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-04.csv']\\n\",\n",
    "      \"Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-05.csv']\\n\",\n",
    "      \"Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-06.csv']\\n\",\n",
    "      \"Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-07.csv']\\n\",\n",
    "      \"Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-08.csv']\\n\",\n",
    "      \"Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-09.csv']\\n\",\n",
    "      \"Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-10.csv']\\n\",\n",
    "      \"Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-11.csv']\\n\",\n",
    "      \"Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-12.csv']\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"from tests.test_utils import load_data_into_test_database\\n\",\n",
    "    \"from typing import List\\n\",\n",
    "    \"import sqlalchemy as sa\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"CONNECTION_STRING = \\\"postgresql+psycopg2://postgres:@localhost/test_ci\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"data_paths: List[str] = [\\n\",\n",
    "    \"     \\\"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-01.csv\\\",\\n\",\n",
    "    \"     \\\"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-02.csv\\\",\\n\",\n",
    "    \"     \\\"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-03.csv\\\",\\n\",\n",
    "    \"     \\\"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-04.csv\\\",\\n\",\n",
    "    \"     \\\"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-05.csv\\\",\\n\",\n",
    "    \"     \\\"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-06.csv\\\",\\n\",\n",
    "    \"     \\\"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-07.csv\\\",\\n\",\n",
    "    \"     \\\"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-08.csv\\\",\\n\",\n",
    "    \"     \\\"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-09.csv\\\",\\n\",\n",
    "    \"     \\\"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-10.csv\\\",\\n\",\n",
    "    \"     \\\"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-11.csv\\\",\\n\",\n",
    "    \"     \\\"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-12.csv\\\",\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"engine = sa.create_engine(CONNECTION_STRING)\\n\",\n",
    "    \"connection = engine.connect()\\n\",\n",
    "    \"table_name = \\\"yellow_tripdata_sample_2020\\\"\\n\",\n",
    "    \"res = connection.execute(f\\\"DROP TABLE IF EXISTS {table_name}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"for data_path in data_paths:\\n\",\n",
    "    \"    # This utility is not for general use. It is only to support testing.\\n\",\n",
    "    \"    load_data_into_test_database(\\n\",\n",
    "    \"        table_name=\\\"yellow_tripdata_sample_2020\\\",\\n\",\n",
    "    \"        csv_path=data_path,\\n\",\n",
    "    \"        connection_string=CONNECTION_STRING,\\n\",\n",
    "    \"        load_full_dataset=True,\\n\",\n",
    "    \"        drop_existing_table=False,\\n\",\n",
    "    \"        convert_colnames_to_datetime=[\\\"pickup_datetime\\\", \\\"dropoff_datetime\\\"]\\n\",\n",
    "    \"    )\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"6d4815f2\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3 (ipykernel)\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.3\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}