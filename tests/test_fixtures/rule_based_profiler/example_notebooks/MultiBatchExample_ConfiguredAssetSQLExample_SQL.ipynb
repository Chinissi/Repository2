{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f0a5264-b003-4101-862f-45653f2aed1b",
   "metadata": {},
   "source": [
    "# How to write multi-batch `BatchRequest` - Configured `Sql` Example\n",
    "* A `BatchRequest` facilitates the return of a `batch` of data from a configured `Datasource`. To find more about `Batches`, please refer to the [related documentation](https://docs.greatexpectations.io/docs/guides/connecting_to_your_data/how_to_get_a_batch_of_data_from_a_configured_datasource#1-construct-a-batchrequest). \n",
    "* A `BatchRequest` can return 0 or more Batches of data depending on the underlying data, and how it is configured. This guide will help you configure `BatchRequests` to return multiple batches, which can be used by\n",
    "   1. Self-Initializing Expectations to estimate parameters\n",
    "   2. DataAssistants to profile your data and create and Expectation suite with self-intialized parameters.\n",
    "   \n",
    "* Note : Multi-batch BatchRequests are not supported in `RuntimeDataConnector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee54886b-4f88-46d9-9afe-dfd8bb061e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "from ruamel import yaml\n",
    "from great_expectations.core.batch import BatchRequest\n",
    "import sqlite3\n",
    "import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa243d2-6905-403a-b47a-d89ba834b951",
   "metadata": {},
   "source": [
    "* Load `DataContext`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45b1854b-2a75-422e-83bb-5509d868e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_context: ge.DataContext = ge.get_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4462320-d76e-492c-96fb-f0ff8f788851",
   "metadata": {},
   "source": [
    "## Sql Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e04726",
   "metadata": {},
   "source": [
    "### Example Database\n",
    "\n",
    "Imagine we have a database of 1 table, with `yellow_tripdata_sample_2020`, corresponding to all 12 months' `taxi_trip` data for 2020.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd29b60b-7e16-4978-acee-0dab368cde3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yellow_tripdata_sample_2020']\n"
     ]
    }
   ],
   "source": [
    "# connect to sqlite DB, and print the existing tables\n",
    "CONNECTION_STRING = \"postgresql+psycopg2://postgres:@localhost/test_ci\"\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "engine = create_engine(CONNECTION_STRING)\n",
    "insp = inspect(engine)\n",
    "print(insp.get_table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49515697-83a2-432d-8b74-33e2f01db72c",
   "metadata": {},
   "source": [
    "## Example Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df19a29c",
   "metadata": {},
   "source": [
    "In our example, we add a `Datasource` named `taxi_multi_batch_sql_datasource` with 1 table. We also have a `ConfiguredAssetSqlDataConnector` named `configured_data_connector_multi_batch_asset`.\n",
    "\n",
    "The DataConnector contains 2 `assets`, both associated with the `table_name` named`yellow_tripdata_sample_2020`.\n",
    "\n",
    "The asset `yellow_tripdata_sample_2020_full` contains no other parameter other than the `table_name` and optional `schema_name`, which mean the whole table will be loaded as one Batch in the asset. \n",
    "\n",
    "The asset `yellow_tripdata_sample_2020_by_year_and_month` contains `table_name` and `schema_name`, as well as splitter configuration. The splitter we use is `split_on_year_and_month`, which creates Batches according to the `pickup_datetime` column which of type timestamp in the database schema.\n",
    "\n",
    "**Note**: This example only uses `splitters` but sampling can also be used. For more information, please refer to the document [How to configure a DataConnector for splitting and sampling tables in SQL](https://docs.greatexpectations.io/docs/guides/connecting_to_your_data/advanced/how_to_configure_a_dataconnector_for_splitting_and_sampling_tables_in_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84150f65-bbd6-4b45-95ab-9590a29f116a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to instantiate class from config...\n",
      "\tInstantiating as a Datasource, since class_name is Datasource\n",
      "\tSuccessfully instantiated Datasource\n",
      "\n",
      "\n",
      "ExecutionEngine class name: SqlAlchemyExecutionEngine\n",
      "Data Connectors:\n",
      "\tconfigured_data_connector_multi_batch_asset : ConfiguredAssetSqlDataConnector\n",
      "\n",
      "\tAvailable data_asset_names (2 of 2):\n",
      "\t\tyellow_tripdata_sample_2020_by_year_and_month (3 of 12): [{'pickup_datetime': {'year': 2020, 'month': 1}}, {'pickup_datetime': {'year': 2020, 'month': 10}}, {'pickup_datetime': {'year': 2020, 'month': 11}}]\n",
      "\t\tyellow_tripdata_sample_2020_full (1 of 1): [{}]\n",
      "\n",
      "\tUnmatched data_references (0 of 0):[]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<great_expectations.datasource.new_datasource.Datasource at 0x7fa3710fd0a0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasource_config = {\n",
    "    \"name\": \"taxi_multi_batch_sql_datasource\",\n",
    "    \"class_name\": \"Datasource\",\n",
    "    \"module_name\": \"great_expectations.datasource\",\n",
    "    \"execution_engine\": {\n",
    "        \"module_name\": \"great_expectations.execution_engine\",\n",
    "        \"class_name\": \"SqlAlchemyExecutionEngine\",\n",
    "        \"connection_string\": CONNECTION_STRING,\n",
    "    },\n",
    "    \"data_connectors\": {\n",
    "        \"configured_data_connector_multi_batch_asset\": {\n",
    "            \"class_name\": \"ConfiguredAssetSqlDataConnector\",\n",
    "            \"assets\":{\n",
    "                \"yellow_tripdata_sample_2020_full\":\n",
    "                {\n",
    "                    \"table_name\": \"yellow_tripdata_sample_2020\",\n",
    "                    \"schema_name\": \"public\",\n",
    "                },\n",
    "    \n",
    "                \"yellow_tripdata_sample_2020_by_year_and_month\":{\n",
    "                    \"table_name\": \"yellow_tripdata_sample_2020\",\n",
    "                    \"schema_name\": \"public\",\n",
    "                    \"splitter_method\": \"split_on_year_and_month\",\n",
    "                    \"splitter_kwargs\": {\n",
    "                        \"column_name\": \"pickup_datetime\",\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "            \n",
    "        },\n",
    "}\n",
    "\n",
    "data_context.test_yaml_config(yaml.dump(datasource_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635755a4-36b1-442f-968a-2fbdb9b146d8",
   "metadata": {},
   "source": [
    "We see we have successfully configured this because the output shows a 2 data assets\n",
    "- `yellow_tripdata_sample_2020_full` associated with 1 batch. \n",
    "- `yellow_tripdata_sample_2020_by_year_and_month` with 12 batches, each associated with a different month in our `pickup_datetime` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7636ffff-0ddc-48fd-a4cf-f8e139a5e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_datasource only if it doesn't already exist in our configuration\n",
    "try:\n",
    "    data_context.get_datasource(datasource_config[\"name\"])\n",
    "except ValueError:\n",
    "    data_context.add_datasource(**datasource_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438146be",
   "metadata": {},
   "source": [
    "## BatchRequest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117cdb0d",
   "metadata": {},
   "source": [
    "Depending on how we configured our assets, when you send a `BatchRequest`, you will retrieve a different number of `Batches`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bc9c59",
   "metadata": {},
   "source": [
    "Single Batch returned by `yellow_tripdata_sample_2020_full`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0453cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch_batch_request: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_sql_datasource\",\n",
    "    data_connector_name=\"configured_data_connector_multi_batch_asset\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020_full\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35df7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = data_context.get_batch_list(batch_request=single_batch_batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8e74a05-3fd1-4e47-9105-b721dbcf3516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<great_expectations.core.batch.Batch at 0x7fa3865e2c10>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7f4fa5",
   "metadata": {},
   "source": [
    "Multi Batch returned by `yellow_tripdata_sample_2020_by_year_and_month`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c32dbac9-af5d-4677-98f9-f098ef091b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_request: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_sql_datasource\",\n",
    "    data_connector_name=\"configured_data_connector_multi_batch_asset\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020_by_year_and_month\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a284bfd-00aa-4068-bc09-71c6dea627e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_list = data_context.get_batch_list(batch_request=multi_batch_batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bf3e1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<great_expectations.core.batch.Batch at 0x7fa3865ea280>,\n",
       " <great_expectations.core.batch.Batch at 0x7fa3720b3670>,\n",
       " <great_expectations.core.batch.Batch at 0x7fa36db1b3d0>,\n",
       " <great_expectations.core.batch.Batch at 0x7fa371845550>,\n",
       " <great_expectations.core.batch.Batch at 0x7fa37106a3d0>,\n",
       " <great_expectations.core.batch.Batch at 0x7fa36de41040>,\n",
       " <great_expectations.core.batch.Batch at 0x7fa372099c70>,\n",
       " <great_expectations.core.batch.Batch at 0x7fa371845730>,\n",
       " <great_expectations.core.batch.Batch at 0x7fa37107c3a0>,\n",
       " <great_expectations.core.batch.Batch at 0x7fa370ffa250>,\n",
       " <great_expectations.core.batch.Batch at 0x7fa371635ca0>,\n",
       " <great_expectations.core.batch.Batch at 0x7fa37108a880>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_batch_batch_list # 12 batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790746ee",
   "metadata": {},
   "source": [
    "You can also get a single Batch from a multi-batch DataConnector by passing in `data_connector_query`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16612bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch_batch_request_from_multi: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_sql_datasource\",\n",
    "    data_connector_name=\"configured_data_connector_multi_batch_asset\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020_by_year_and_month\",\n",
    "    data_connector_query={ \n",
    "        \"batch_filter_parameters\": {\"pickup_datetime\": {\"year\": 2020, \"month\": 1}}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ef1b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = data_context.get_batch_list(batch_request=single_batch_batch_request_from_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "229815cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': '<great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fa3710cdbb0>',\n",
       " 'batch_request': {'datasource_name': 'taxi_multi_batch_sql_datasource',\n",
       "  'data_connector_name': 'configured_data_connector_multi_batch_asset',\n",
       "  'data_asset_name': 'yellow_tripdata_sample_2020_by_year_and_month',\n",
       "  'limit': None,\n",
       "  'batch_spec_passthrough': None,\n",
       "  'data_connector_query': {'batch_filter_parameters': {'pickup_datetime': {'year': 2020,\n",
       "     'month': 1}}}},\n",
       " 'batch_definition': {'datasource_name': 'taxi_multi_batch_sql_datasource',\n",
       "  'data_connector_name': 'configured_data_connector_multi_batch_asset',\n",
       "  'data_asset_name': 'yellow_tripdata_sample_2020_by_year_and_month',\n",
       "  'batch_identifiers': {'pickup_datetime': {'year': 2020, 'month': 1}}},\n",
       " 'batch_spec': {'data_asset_name': 'yellow_tripdata_sample_2020_by_year_and_month',\n",
       "  'table_name': 'yellow_tripdata_sample_2020',\n",
       "  'batch_identifiers': {'pickup_datetime': {'year': 2020, 'month': 1}},\n",
       "  'schema_name': 'public',\n",
       "  'module_name': 'great_expectations.datasource.data_connector.asset',\n",
       "  'splitter_kwargs': {'column_name': 'pickup_datetime'},\n",
       "  'splitter_method': 'split_on_year_and_month',\n",
       "  'class_name': 'Asset',\n",
       "  'type': None},\n",
       " 'batch_markers': {'ge_load_time': '20220907T222335.730131Z'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_list[0].to_dict() # 'batch_identifiers': {'pickup_datetime': '2020-01'}},"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907a6ef5",
   "metadata": {},
   "source": [
    "# Using auto-initializing `Expectations` to generate parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe9c76",
   "metadata": {},
   "source": [
    "We will generate a `Validator` using our `multi_batch_batch_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "847ce4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_list = data_context.get_batch_list(batch_request=multi_batch_batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1eca55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_suite = data_context.create_expectation_suite(expectation_suite_name=\"example_sql_suite\", overwrite_existing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "852deba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = data_context.get_validator_using_batch_list(batch_list=multi_batch_batch_list, expectation_suite=example_suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee01a0e9",
   "metadata": {},
   "source": [
    "When you run methods on the validator, it will typically run on the most recent batch (index `-1`), even if the Validator has access to a longer Batch list. For example, notice that rows below are all associated with `pickup_datetime` being `9` (September, 2020). This is because the datetime values are stored lexicographically, meaning `1` and `11`, `12` values will appear **before** `2` and `3`.\n",
    "\n",
    "**NOTE** This will be fixed in time for the `DataAssistant` release"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7d827-ed51-4f83-ac41-33ae58416ef1",
   "metadata": {},
   "source": [
    "For simplicity, let's get a `validator` with the December `Batch`, which is in index `\"3\"` (after `1`, `10`, `11`). Notice that we are also casting the value as a `list` using the square brackets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11b673bc-8583-4fc5-9aa0-db6ca62e240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = data_context.get_validator_using_batch_list(batch_list=[multi_batch_batch_list[3]], expectation_suite=example_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffe9cabd-b2bd-46de-9317-ba4e809342fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac2d57b8395419cbd63d1de0bd4d61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>rate_code_id</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>dropoff_location_id</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-12-15 12:20:27</td>\n",
       "      <td>2020-12-15 12:40:49</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>209</td>\n",
       "      <td>237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>26.80</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-12-28 12:51:25</td>\n",
       "      <td>2020-12-28 13:15:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>44.60</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-12-27 10:43:42</td>\n",
       "      <td>2020-12-27 10:51:05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>163</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.36</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-12-08 13:42:52</td>\n",
       "      <td>2020-12-08 13:54:45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>137</td>\n",
       "      <td>229</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.30</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-12-19 11:56:43</td>\n",
       "      <td>2020-12-19 12:08:43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>24</td>\n",
       "      <td>74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendor_id     pickup_datetime    dropoff_datetime  passenger_count  \\\n",
       "0        2.0 2020-12-15 12:20:27 2020-12-15 12:40:49              4.0   \n",
       "1        2.0 2020-12-28 12:51:25 2020-12-28 13:15:12              1.0   \n",
       "2        2.0 2020-12-27 10:43:42 2020-12-27 10:51:05              1.0   \n",
       "3        2.0 2020-12-08 13:42:52 2020-12-08 13:54:45              1.0   \n",
       "4        2.0 2020-12-19 11:56:43 2020-12-19 12:08:43              1.0   \n",
       "\n",
       "   trip_distance  rate_code_id store_and_fwd_flag  pickup_location_id  \\\n",
       "0           5.76           1.0                  N                 209   \n",
       "1          11.64           1.0                  N                 161   \n",
       "2           1.22           1.0                  N                 163   \n",
       "3           1.84           1.0                  N                 137   \n",
       "4           1.55           1.0                  N                  24   \n",
       "\n",
       "   dropoff_location_id  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                  237           1.0         21.0    0.0      0.5        2.50   \n",
       "1                  220           1.0         33.5    0.0      0.5        5.00   \n",
       "2                   48           1.0          7.0    0.0      0.5        2.06   \n",
       "3                  229           2.0          9.0    0.0      0.5        0.00   \n",
       "4                   74           1.0          9.5    0.0      0.5        2.58   \n",
       "\n",
       "   tolls_amount  improvement_surcharge  total_amount  congestion_surcharge  \n",
       "0           0.0                    0.3         26.80                   2.5  \n",
       "1           2.8                    0.3         44.60                   2.5  \n",
       "2           0.0                    0.3         12.36                   2.5  \n",
       "3           0.0                    0.3         12.30                   2.5  \n",
       "4           0.0                    0.3         12.88                   0.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be66602",
   "metadata": {},
   "source": [
    "### Typical Workflow\n",
    "A `batch_list` becomes really useful when you are calculating parameters for auto-initializing Expectations, as they us a `RuleBasedProfiler` under-the-hood to calculate parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdef9ad7",
   "metadata": {},
   "source": [
    "Here is an example running `expect_column_median_to_be_between()` by \"guessing\" at the `min_value` and `max_value`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b524a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.expect_column_median_to_be_between(column=\"trip_distance\", min_value=0, max_value=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d096f",
   "metadata": {},
   "source": [
    "The observed value for our `yellow_tripdata_sample_2020_01` table where `vendor_id` = `2`  is going to be `1.6`, which means the Expectation fails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5016d8",
   "metadata": {},
   "source": [
    "Now we run the same expectation again, but this time with `auto=True`. This means the `median` values are going to calculated across the `batch_list` associated with the `Validator` (ie 3 Batches for `yellow_tripdata_sample_2020_01`), which gives the min value of `1.5` and the max value of `5.23`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd821c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.expect_column_median_to_be_between(column=\"trip_distance\", auto=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a6c277",
   "metadata": {},
   "source": [
    "The `auto=True` will also automatically run the Expectation against the most recent Batch (which has an observed value of `1.61`) and the Expectation will pass. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8b938",
   "metadata": {},
   "source": [
    "You can now save the `ExpectationSuite`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba880ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.save_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7ec631",
   "metadata": {},
   "source": [
    "### Running the `ExpectationSuite` against single `Batch`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477381f5",
   "metadata": {},
   "source": [
    "Now the ExpectationSuite can be used to validate single batches using a Checkpoint. In our example, let's validate a different table, `yellow_tripdata_sample_2020_02`, using the `ExpectationSuite` we built from `yellow_tripdata_sample_2020_01`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747dea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch_batch_request_from_multi: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_sql_datasource\",\n",
    "    data_connector_name=\"configured_data_connector_multi_batch_asset\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020_by_year_and_month\",\n",
    "    data_connector_query={ \n",
    "        \"batch_filter_parameters\": {\"pickup_datetime\": {\"year\": 2020, \"month\": 2}}\n",
    "    }\n",
    "\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb93d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_config = {\n",
    "    \"name\": \"my_checkpoint\",\n",
    "    \"config_version\": 1,\n",
    "    \"class_name\": \"SimpleCheckpoint\",\n",
    "    \"validations\": [\n",
    "        {\n",
    "            \"batch_request\": single_batch_batch_request_from_multi,\n",
    "            \"expectation_suite_name\": \"example_sql_suite\",            \n",
    "        }\n",
    "    ],\n",
    "}\n",
    "data_context.add_checkpoint(**checkpoint_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = data_context.run_checkpoint(\n",
    "    checkpoint_name=\"my_checkpoint\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6234082",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6737ccdd",
   "metadata": {},
   "source": [
    "# Appendix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6914725d-85cc-4c9d-a93d-2d1c329eac74",
   "metadata": {},
   "source": [
    "## Other Parameters for `ConfiguredAssetSqlDataConnector`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e62691",
   "metadata": {},
   "source": [
    "The signature of the `ConfiguredAssetSqlDataConnector` also contains the following parameters: \n",
    "\n",
    "The following required parameters:\n",
    "* `name`: The name of this DataConnector.\n",
    "* `datasource_name`: The name of the Datasource that contains it.\n",
    "* `execution_engine`: An ExecutionEngine.\n",
    "* `assets`: The dictionary containing the asset configurations.\n",
    "\n",
    "The `assets` dictionary can contain the following keys and values:\n",
    "* `table_name`: string that defines the `table_name` associated with the asset. If table_name is omitted, then the `table_name` defaults to the asset name.\n",
    "* `schema_name`: optional string that defines the `schema` for the asset.\n",
    "* `include_schema_name`: A `bool` that determines, \"Should the `data_asset_name` include the `schema` as a prefix?\"\n",
    "* `splitter_method`: string that names method to split the target table into multiple `Batches`.\n",
    "* `splitter_kwargs`: a dict containing arguments to pass to `splitter_method`.\n",
    "* `sampling_method`: string that names method to downsample within a target `Batch`.\n",
    "* `sampling_kwargs` (dict): Keyword arguments to pass to `sampling_method`.\n",
    "* `batch_spec_passthrough` (dict): dictionary with keys that will be added directly to `batch_spec`.\n",
    "\n",
    "\n",
    "For more information on `splitters` and `samplers` please consider the following documentation:[How to configure a DataConnector for splitting and sampling tables in SQL](https://docs.greatexpectations.io/docs/guides/connecting_to_your_data/advanced/how_to_configure_a_dataconnector_for_splitting_and_sampling_tables_in_sql)\n",
    "\n",
    "**Note**: although \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ecebdc",
   "metadata": {},
   "source": [
    "# Loading Data into Postgresql Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a183e-f0df-40f4-b64f-439666e32ab4",
   "metadata": {},
   "source": [
    "* The following code can be used to build the postgres database used in this notebook. It is included (and commented out) for reference.\n",
    "* In order to load the data into a local `postgresql` database, please feel free to use the `docker-compose.yml` file available at `great_expectations/assets/docker/postgresql/`. \n",
    "\n",
    "### To spin up the `postgresql` database\n",
    "* Have [Docker Desktop](https://www.docker.com/products/docker-desktop/) running locally.\n",
    "* Navigate to `great_expectations/assets/docker/postgresql/`\n",
    "* Type `docker-compose up`\n",
    "* Then uncomment and run the following snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad91c234-06a2-4e98-9d90-c999c2aad07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-01.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-02.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-03.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-04.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-05.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-06.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-07.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-08.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-09.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-10.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-11.csv']\n",
      "Adding to existing table yellow_tripdata_sample_2020 and adding data from ['../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-12.csv']\n"
     ]
    }
   ],
   "source": [
    "# from tests.test_utils import load_data_into_test_database\n",
    "# from typing import List\n",
    "# import sqlalchemy as sa\n",
    "# import pandas as pd\n",
    "# CONNECTION_STRING = \"postgresql+psycopg2://postgres:@localhost/test_ci\"\n",
    "\n",
    "# data_paths: List[str] = [\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-01.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-02.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-03.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-04.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-05.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-06.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-07.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-08.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-09.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-10.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-11.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-12.csv\",\n",
    "# ]\n",
    "\n",
    "    \n",
    "# engine = sa.create_engine(CONNECTION_STRING)\n",
    "# connection = engine.connect()\n",
    "# table_name = \"yellow_tripdata_sample_2020\"\n",
    "# res = connection.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "\n",
    "# for data_path in data_paths:\n",
    "#     # This utility is not for general use. It is only to support testing.\n",
    "#     load_data_into_test_database(\n",
    "#         table_name=\"yellow_tripdata_sample_2020\",\n",
    "#         csv_path=data_path,\n",
    "#         connection_string=CONNECTION_STRING,\n",
    "#         load_full_dataset=True,\n",
    "#         drop_existing_table=False,\n",
    "#         convert_colnames_to_datetime=[\"pickup_datetime\", \"dropoff_datetime\"]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d3086",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
