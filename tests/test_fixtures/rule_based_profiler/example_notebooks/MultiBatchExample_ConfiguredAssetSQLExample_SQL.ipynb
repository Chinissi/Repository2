{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f0a5264-b003-4101-862f-45653f2aed1b",
   "metadata": {},
   "source": [
    "# How to write multi-batch `BatchRequest` - Configured `Sql` Example\n",
    "* A `BatchRequest` facilitates the return of a `batch` of data from a configured `Datasource`. To find more about `Batches`, please refer to the [related documentation](https://docs.greatexpectations.io/docs/guides/connecting_to_your_data/how_to_get_a_batch_of_data_from_a_configured_datasource#1-construct-a-batchrequest). \n",
    "* A `BatchRequest` can return 0 or more Batches of data depending on the underlying data, and how it is configured. This guide will help you configure `BatchRequests` to return multiple batches, which can be used by\n",
    "   1. Self-Initializing Expectations to estimate parameters\n",
    "   2. DataAssistants to profile your data and create and Expectation suite with self-intialized parameters.\n",
    "   \n",
    "* Note : Multi-batch BatchRequests are not supported in `RuntimeDataConnector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee54886b-4f88-46d9-9afe-dfd8bb061e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "from ruamel import yaml\n",
    "from great_expectations.core.batch import BatchRequest\n",
    "import sqlite3\n",
    "import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa243d2-6905-403a-b47a-d89ba834b951",
   "metadata": {},
   "source": [
    "* Load `DataContext`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1854b-2a75-422e-83bb-5509d868e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_context: ge.DataContext = ge.get_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4462320-d76e-492c-96fb-f0ff8f788851",
   "metadata": {},
   "source": [
    "## Sql Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e04726",
   "metadata": {},
   "source": [
    "### Example Database\n",
    "\n",
    "Imagine we have a database of 1 table, with `yellow_tripdata_sample_2020`, corresponding to all 12 months' `taxi_trip` data for 2020.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd29b60b-7e16-4978-acee-0dab368cde3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to sqlite DB, and print the existing tables\n",
    "CONNECTION_STRING = \"postgresql+psycopg2://postgres:@localhost/test_ci\"\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "engine = create_engine(CONNECTION_STRING)\n",
    "insp = inspect(engine)\n",
    "print(insp.get_table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49515697-83a2-432d-8b74-33e2f01db72c",
   "metadata": {},
   "source": [
    "## Example Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df19a29c",
   "metadata": {},
   "source": [
    "In our example, we add a `Datasource` named `taxi_multi_batch_sql_datasource` with 1 table. We also have a `ConfiguredAssetSqlDataConnector` named `configured_data_connector_multi_batch_asset`.\n",
    "\n",
    "The DataConnector contains 2 `assets`, both associated with the `table_name` named`yellow_tripdata_sample_2020`.\n",
    "\n",
    "The asset `yellow_tripdata_sample_2020_full` contains no other parameter other than the `table_name` and optional `schema_name`, which mean the whole table will be loaded as one Batch in the asset. \n",
    "\n",
    "The asset `yellow_tripdata_sample_2020_by_year_and_month` contains `table_name` and `schema_name`, as well as splitter configuration. The splitter we use is `split_on_year_and_month`, which creates Batches according to the `pickup_datetime` column which of type timestamp in the database schema.\n",
    "\n",
    "**Note**: This example only uses `splitters` but sampling can also be used. For more information, please refer to the document [How to configure a DataConnector for splitting and sampling tables in SQL](https://docs.greatexpectations.io/docs/guides/connecting_to_your_data/advanced/how_to_configure_a_dataconnector_for_splitting_and_sampling_tables_in_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84150f65-bbd6-4b45-95ab-9590a29f116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource_config = {\n",
    "    \"name\": \"taxi_multi_batch_sql_datasource\",\n",
    "    \"class_name\": \"Datasource\",\n",
    "    \"module_name\": \"great_expectations.datasource\",\n",
    "    \"execution_engine\": {\n",
    "        \"module_name\": \"great_expectations.execution_engine\",\n",
    "        \"class_name\": \"SqlAlchemyExecutionEngine\",\n",
    "        \"connection_string\": CONNECTION_STRING,\n",
    "    },\n",
    "    \"data_connectors\": {\n",
    "        \"configured_data_connector_multi_batch_asset\": {\n",
    "            \"class_name\": \"ConfiguredAssetSqlDataConnector\",\n",
    "            \"assets\":{\n",
    "                \"yellow_tripdata_sample_2020_full\":\n",
    "                {\n",
    "                    \"table_name\": \"yellow_tripdata_sample_2020\",\n",
    "                    \"schema_name\": \"public\",\n",
    "                },\n",
    "    \n",
    "                \"yellow_tripdata_sample_2020_by_year_and_month\":{\n",
    "                    \"table_name\": \"yellow_tripdata_sample_2020\",\n",
    "                    \"schema_name\": \"public\",\n",
    "                    \"splitter_method\": \"split_on_year_and_month\",\n",
    "                    \"splitter_kwargs\": {\n",
    "                        \"column_name\": \"pickup_datetime\",\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "            \n",
    "        },\n",
    "}\n",
    "\n",
    "data_context.test_yaml_config(yaml.dump(datasource_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635755a4-36b1-442f-968a-2fbdb9b146d8",
   "metadata": {},
   "source": [
    "We see we have successfully configured this because the output shows a 2 data assets\n",
    "- `yellow_tripdata_sample_2020_full` associated with 1 batch. \n",
    "- `yellow_tripdata_sample_2020_by_year_and_month` with 12 batches, each associated with a different month in our `pickup_datetime` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7636ffff-0ddc-48fd-a4cf-f8e139a5e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_datasource only if it doesn't already exist in our configuration\n",
    "try:\n",
    "    data_context.get_datasource(datasource_config[\"name\"])\n",
    "except ValueError:\n",
    "    data_context.add_datasource(**datasource_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438146be",
   "metadata": {},
   "source": [
    "## BatchRequest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117cdb0d",
   "metadata": {},
   "source": [
    "Depending on how we configured our assets, when you send a `BatchRequest`, you will retrieve a different number of `Batches`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bc9c59",
   "metadata": {},
   "source": [
    "Single Batch returned by `yellow_tripdata_sample_2020_full`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0453cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch_batch_request: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_sql_datasource\",\n",
    "    data_connector_name=\"configured_data_connector_multi_batch_asset\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020_full\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = data_context.get_batch_list(batch_request=single_batch_batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e74a05-3fd1-4e47-9105-b721dbcf3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7f4fa5",
   "metadata": {},
   "source": [
    "Multi Batch returned by `yellow_tripdata_sample_2020_by_year_and_month`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32dbac9-af5d-4677-98f9-f098ef091b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_request: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_sql_datasource\",\n",
    "    data_connector_name=\"configured_data_connector_multi_batch_asset\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020_by_year_and_month\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a284bfd-00aa-4068-bc09-71c6dea627e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_list = data_context.get_batch_list(batch_request=multi_batch_batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf3e1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_list # 12 batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790746ee",
   "metadata": {},
   "source": [
    "You can also get a single Batch from a multi-batch DataConnector by passing in `data_connector_query`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16612bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch_batch_request_from_multi: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_sql_datasource\",\n",
    "    data_connector_name=\"configured_data_connector_multi_batch_asset\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020_by_year_and_month\",\n",
    "    data_connector_query={ \n",
    "        \"batch_filter_parameters\": {\"pickup_datetime\": {\"year\": 2020, \"month\": 1}}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef1b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = data_context.get_batch_list(batch_request=single_batch_batch_request_from_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229815cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list[0].to_dict() # 'batch_identifiers': {'pickup_datetime': '2020-01'}},"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907a6ef5",
   "metadata": {},
   "source": [
    "# Using auto-initializing `Expectations` to generate parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe9c76",
   "metadata": {},
   "source": [
    "We will generate a `Validator` using our `multi_batch_batch_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ce4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_list = data_context.get_batch_list(batch_request=multi_batch_batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eca55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_suite = data_context.create_expectation_suite(expectation_suite_name=\"example_sql_suite\", overwrite_existing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852deba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = data_context.get_validator_using_batch_list(batch_list=multi_batch_batch_list, expectation_suite=example_suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee01a0e9",
   "metadata": {},
   "source": [
    "When you run methods on the validator, it will typically run on the most recent batch (index `-1`), even if the Validator has access to a longer Batch list. For example, notice that rows below are all associated with `pickup_datetime` being `9` (September, 2020). This is because the datetime values are stored lexicographically, meaning `1` and `11`, `12` values will appear **before** `2` and `3`.\n",
    "\n",
    "**NOTE** This will be fixed in time for the `DataAssistant` release"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7d827-ed51-4f83-ac41-33ae58416ef1",
   "metadata": {},
   "source": [
    "For simplicity, let's get a `validator` with the December `Batch`, which is in index `\"3\"` (after `1`, `10`, `11`). Notice that we are also casting the value as a `list` using the square brackets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b673bc-8583-4fc5-9aa0-db6ca62e240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = data_context.get_validator_using_batch_list(batch_list=[multi_batch_batch_list[3]], expectation_suite=example_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9cabd-b2bd-46de-9317-ba4e809342fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be66602",
   "metadata": {},
   "source": [
    "### Typical Workflow\n",
    "A `batch_list` becomes really useful when you are calculating parameters for auto-initializing Expectations, as they us a `RuleBasedProfiler` under-the-hood to calculate parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdef9ad7",
   "metadata": {},
   "source": [
    "Here is an example running `expect_column_median_to_be_between()` by \"guessing\" at the `min_value` and `max_value`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b524a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.expect_column_median_to_be_between(column=\"trip_distance\", min_value=0, max_value=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d096f",
   "metadata": {},
   "source": [
    "The observed value for our `yellow_tripdata_sample_2020_01` table where `vendor_id` = `2`  is going to be `1.6`, which means the Expectation fails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5016d8",
   "metadata": {},
   "source": [
    "Now we run the same expectation again, but this time with `auto=True`. This means the `median` values are going to calculated across the `batch_list` associated with the `Validator` (ie 3 Batches for `yellow_tripdata_sample_2020_01`), which gives the min value of `1.5` and the max value of `5.23`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd821c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.expect_column_median_to_be_between(column=\"trip_distance\", auto=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a6c277",
   "metadata": {},
   "source": [
    "The `auto=True` will also automatically run the Expectation against the most recent Batch (which has an observed value of `1.61`) and the Expectation will pass. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8b938",
   "metadata": {},
   "source": [
    "You can now save the `ExpectationSuite`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba880ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.save_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7ec631",
   "metadata": {},
   "source": [
    "### Running the `ExpectationSuite` against single `Batch`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477381f5",
   "metadata": {},
   "source": [
    "Now the ExpectationSuite can be used to validate single batches using a Checkpoint. In our example, let's validate a different table, `yellow_tripdata_sample_2020_02`, using the `ExpectationSuite` we built from `yellow_tripdata_sample_2020_01`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747dea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch_batch_request_from_multi: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_sql_datasource\",\n",
    "    data_connector_name=\"configured_data_connector_multi_batch_asset\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020_by_year_and_month\",\n",
    "    data_connector_query={ \n",
    "        \"batch_filter_parameters\": {\"pickup_datetime\": {\"year\": 2020, \"month\": 2}}\n",
    "    }\n",
    "\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb93d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_config = {\n",
    "    \"name\": \"my_checkpoint\",\n",
    "    \"config_version\": 1,\n",
    "    \"class_name\": \"SimpleCheckpoint\",\n",
    "    \"validations\": [\n",
    "        {\n",
    "            \"batch_request\": single_batch_batch_request_from_multi,\n",
    "            \"expectation_suite_name\": \"example_sql_suite\",            \n",
    "        }\n",
    "    ],\n",
    "}\n",
    "data_context.add_checkpoint(**checkpoint_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = data_context.run_checkpoint(\n",
    "    checkpoint_name=\"my_checkpoint\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6234082",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6737ccdd",
   "metadata": {},
   "source": [
    "# Appendix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6914725d-85cc-4c9d-a93d-2d1c329eac74",
   "metadata": {},
   "source": [
    "## Other Parameters for `ConfiguredAssetSqlDataConnector`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e62691",
   "metadata": {},
   "source": [
    "The signature of the `ConfiguredAssetSqlDataConnector` also contains the following parameters: \n",
    "\n",
    "The following required parameters:\n",
    "* `name`: The name of this DataConnector.\n",
    "* `datasource_name`: The name of the Datasource that contains it.\n",
    "* `execution_engine`: An ExecutionEngine.\n",
    "* `assets`: The dictionary containing the asset configurations.\n",
    "\n",
    "The `assets` dictionary can contain the following keys and values:\n",
    "* `table_name`: string that defines the `table_name` associated with the asset. If table_name is omitted, then the `table_name` defaults to the asset name.\n",
    "* `schema_name`: optional string that defines the `schema` for the asset.\n",
    "* `include_schema_name`: A `bool` that determines, \"Should the `data_asset_name` include the `schema` as a prefix?\"\n",
    "* `splitter_method`: string that names method to split the target table into multiple `Batches`.\n",
    "* `splitter_kwargs`: a dict containing arguments to pass to `splitter_method`.\n",
    "* `sampling_method`: string that names method to downsample within a target `Batch`.\n",
    "* `sampling_kwargs` (dict): Keyword arguments to pass to `sampling_method`.\n",
    "* `batch_spec_passthrough` (dict): dictionary with keys that will be added directly to `batch_spec`.\n",
    "\n",
    "\n",
    "For more information on `splitters` and `samplers` please consider the following documentation:[How to configure a DataConnector for splitting and sampling tables in SQL](https://docs.greatexpectations.io/docs/guides/connecting_to_your_data/advanced/how_to_configure_a_dataconnector_for_splitting_and_sampling_tables_in_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ecebdc",
   "metadata": {},
   "source": [
    "# Loading Data into Postgresql Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a183e-f0df-40f4-b64f-439666e32ab4",
   "metadata": {},
   "source": [
    "* The following code can be used to build the postgres database used in this notebook. It is included (and commented out) for reference.\n",
    "* In order to load the data into a local `postgresql` database, please feel free to use the `docker-compose.yml` file available at `great_expectations/assets/docker/postgresql/`. \n",
    "\n",
    "### To spin up the `postgresql` database\n",
    "* Have [Docker Desktop](https://www.docker.com/products/docker-desktop/) running locally.\n",
    "* Navigate to `great_expectations/assets/docker/postgresql/`\n",
    "* Type `docker-compose up`\n",
    "* Then uncomment and run the following snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91c234-06a2-4e98-9d90-c999c2aad07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tests.test_utils import load_data_into_test_database\n",
    "# from typing import List\n",
    "# import sqlalchemy as sa\n",
    "# import pandas as pd\n",
    "# CONNECTION_STRING = \"postgresql+psycopg2://postgres:@localhost/test_ci\"\n",
    "\n",
    "# data_paths: List[str] = [\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-01.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-02.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-03.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-04.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-05.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-06.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-07.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-08.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-09.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-10.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-11.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-12.csv\",\n",
    "# ]\n",
    "\n",
    "    \n",
    "# engine = sa.create_engine(CONNECTION_STRING)\n",
    "# connection = engine.connect()\n",
    "# table_name = \"yellow_tripdata_sample_2020\"\n",
    "# res = connection.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "\n",
    "# for data_path in data_paths:\n",
    "#     # This utility is not for general use. It is only to support testing.\n",
    "#     load_data_into_test_database(\n",
    "#         table_name=\"yellow_tripdata_sample_2020\",\n",
    "#         csv_path=data_path,\n",
    "#         connection_string=CONNECTION_STRING,\n",
    "#         load_full_dataset=True,\n",
    "#         drop_existing_table=False,\n",
    "#         convert_colnames_to_datetime=[\"pickup_datetime\", \"dropoff_datetime\"]\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
