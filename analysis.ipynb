{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e51e733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Great Expectations ==========\n",
      "('expect_column_kl_divergence_to_be_less_than', 450, 'great_expectations/dataset/dataset.py')\n",
      "('get_dataset', 424, 'great_expectations/self_check/util.py')\n",
      "('test_yaml_config', 401, 'great_expectations/data_context/data_context.py')\n",
      "('_register_metric_functions', 396, 'great_expectations/expectations/metrics/map_metric_provider.py')\n",
      "('_validate', 358, 'great_expectations/expectations/core/expect_column_kl_divergence_to_be_less_than.py')\n",
      "('validate', 328, 'great_expectations/data_asset/data_asset.py')\n",
      "('generate_expectation_tests', 309, 'great_expectations/self_check/util.py')\n",
      "('validate', 279, 'great_expectations/validator/validator.py')\n",
      "('column_condition_partial', 245, 'great_expectations/expectations/metrics/map_metric_provider.py')\n",
      "('validation_operator_run', 244, 'great_expectations/cli/v012/validation_operator.py')\n",
      "('profile_datasource', 231, 'great_expectations/data_context/data_context.py')\n",
      "('column_pair_condition_partial', 226, 'great_expectations/expectations/metrics/map_metric_provider.py')\n",
      "('render', 217, 'great_expectations/render/renderer/content_block/content_block.py')\n",
      "('column_function_partial', 214, 'great_expectations/expectations/metrics/map_metric_provider.py')\n",
      "('multicolumn_condition_partial', 211, 'great_expectations/expectations/metrics/map_metric_provider.py')\n",
      "('_profile', 206, 'great_expectations/profile/basic_dataset_profiler.py')\n",
      "('column_pair_function_partial', 204, 'great_expectations/expectations/metrics/map_metric_provider.py')\n",
      "('multicolumn_function_partial', 199, 'great_expectations/expectations/metrics/map_metric_provider.py')\n",
      "('render', 197, 'great_expectations/render/renderer/page_renderer.py')\n",
      "('expectation', 195, 'great_expectations/data_asset/data_asset.py')\n",
      "\n",
      "========== Tests ==========\n",
      "('numeric_high_card_dict', 1005, 'tests/conftest.py')\n",
      "('bobby_columnar_table_multi_batch', 676, 'tests/rule_based_profiler/bobby_user_workflow_fixture.py')\n",
      "('test_custom_class', 611, 'tests/test_great_expectations.py')\n",
      "('non_numeric_high_card_dataset', 442, 'tests/conftest.py')\n",
      "('test_profile_integer_ranges_schema', 417, 'tests/profile/test_jsonschema_profiler.py')\n",
      "('test_profile_number_ranges_schema', 381, 'tests/profile/test_jsonschema_profiler.py')\n",
      "('test_basic_checkpoint_config_validation', 338, 'tests/checkpoint/test_checkpoint.py')\n",
      "('test_complex_suite_with_batch_request', 338, 'tests/render/renderer/v3/test_suite_edit_notebook_renderer.py')\n",
      "('test_introspect_db', 321, 'tests/datasource/test_new_datasource_with_sql_data_connector.py')\n",
      "('test_newstyle_checkpoint_instantiates_and_produces_a_validation_result_when_run_batch_request_object_multi_validation_pandasdf', 314, 'tests/checkpoint/test_checkpoint.py')\n",
      "('test_SimpleSqlalchemyDatasource', 310, 'tests/datasource/test_new_datasource_with_sql_data_connector.py')\n",
      "('test_format_map_output', 293, 'tests/data_asset/test_data_asset_internals.py')\n",
      "('test_newstyle_checkpoint_config_substitution_nested', 282, 'tests/checkpoint/test_checkpoint.py')\n",
      "('titanic_pandas_data_context_with_v013_datasource_stats_enabled_with_checkpoints_v1_with_templates', 280, 'tests/conftest.py')\n",
      "('test_complex_suite', 279, 'tests/render/renderer/test_suite_edit_notebook_renderer.py')\n",
      "('pytest_generate_tests', 277, 'tests/test_definitions/test_expectations_cfe.py')\n",
      "('test_ValidationResultsTableContentBlockRenderer_get_unexpected_table', 266, 'tests/render/test_render_ValidationResultsTableContentBlockRenderer.py')\n",
      "('test_validate_distribution_parameters', 265, 'tests/dataset/test_dataset_util_legacy.py')\n",
      "('test_configuration_driven_site_builder', 260, 'tests/render/test_data_documentation_site_builder.py')\n",
      "('test_newstyle_checkpoint_config_substitution_simple', 254, 'tests/checkpoint/test_checkpoint.py')\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import glob\n",
    "import re\n",
    "\n",
    "\n",
    "def get_n_longest_funcs(dir, n):\n",
    "    function_definitions = []\n",
    "    for path in glob.glob(f\"{dir}/**/*.py\", recursive=True):\n",
    "        with open(path) as f:\n",
    "            root = ast.parse(f.read(), path)\n",
    "\n",
    "        for node in ast.walk(root):\n",
    "            if isinstance(node, ast.FunctionDef):\n",
    "                length = node.end_lineno - node.lineno\n",
    "                definition = (node.name, length, path)\n",
    "                function_definitions.append(definition)\n",
    "\n",
    "    function_definitions.sort(key=lambda x: x[1], reverse=True)\n",
    "    return function_definitions[:n]\n",
    "\n",
    "\n",
    "print(\"========== Great Expectations ==========\")\n",
    "for func in get_n_longest_funcs(\"great_expectations\", 20):\n",
    "    print(func)\n",
    "\n",
    "print(\"\\n========== Tests ==========\")\n",
    "for func in get_n_longest_funcs(\"tests\", 20):\n",
    "    print(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f154794b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 5909\n",
      "Count Over 0.1s: 984\n",
      "Slowest: [37.34, 16.7, 12.07, 9.79, 9.57, 9.46, 9.39, 9.1, 8.58, 8.47]\n",
      "Mean: 0.12851582332035877\n",
      "Median: 0.01\n",
      "Mode: 0.0\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "def parse_test_results():\n",
    "    with open(\"test_performance.txt\") as f:\n",
    "        contents = f.read()\n",
    "\n",
    "    pattern = r\"(\\d*\\.\\d{2})s call\" # Can check: 'call', 'setup' and 'teardown'\n",
    "    r = re.compile(pattern)\n",
    "\n",
    "    durations = [float(t) for t in r.findall(contents)]\n",
    "    return durations\n",
    "    \n",
    "test_results = parse_test_results()\n",
    "print(f\"Count: {len(test_results)}\")\n",
    "print(f\"Count Over 0.1s: {len([x for x in test_results if x > 0.1])}\")\n",
    "print(f\"Slowest: {test_results[:10]}\")\n",
    "print(f\"Mean: {statistics.mean(test_results)}\")\n",
    "print(f\"Median: {statistics.median(test_results)}\")\n",
    "print(f\"Mode: {statistics.mode(test_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9b2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
